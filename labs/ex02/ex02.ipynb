{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_loss` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w, name=\"MSE\"):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    N = tx.shape[0]\n",
    "    if name == \"MSE\":\n",
    "        return np.sum((y - tx @ w)**2)/2*N\n",
    "    elif name == \"MAE\":\n",
    "        return np.sum(np.absolute((y - tx @ w)))/2*N\n",
    "    else:\n",
    "        raise NotImplementedError "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    for i in range(grid_w0.shape[0]):\n",
    "        for j in range(grid_w1.shape[0]):\n",
    "            w = np.array([grid_w0[i], grid_w1[j]])\n",
    "            l = compute_loss(y, tx, w)\n",
    "            losses[i][j] = l\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=1879354101.9523237, w0*=71.42857142857142, w1*=15.306122448979579, execution time=0.090 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=50)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    N = tx.shape[0]\n",
    "    e = (y - tx @ w)\n",
    "    return -(tx.T @ e)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26.706078  ,  6.52028757])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_gradient(y, tx, w=np.array([100, 20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "\n",
    "        # Compute the gradient and loss\n",
    "        g = compute_gradient(y, tx, w)\n",
    "        loss = compute_loss(y, tx, w)\n",
    "\n",
    "        # Update w\n",
    "        w = w - gamma * g\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=37804738819.875885, w0=94.65878440042104, w1=10.695942486997817\n",
      "GD iter. 1/49: loss=24748924807.998432, w0=90.38581192075787, w1=11.252696476596071\n",
      "GD iter. 2/49: loss=16393203840.396858, w0=86.96743393702734, w1=11.69809966827467\n",
      "GD iter. 3/49: loss=11045542421.131847, w0=84.23273155004291, w1=12.054422221617548\n",
      "GD iter. 4/49: loss=7623039112.802246, w0=82.04496964045536, w1=12.339480264291852\n",
      "GD iter. 5/49: loss=5432636995.471291, w0=80.29476011278533, w1=12.567526698431294\n",
      "GD iter. 6/49: loss=4030779640.3794827, w0=78.8945924906493, w1=12.749963845742846\n",
      "GD iter. 7/49: loss=3133590933.1207285, w0=77.77445839294047, w1=12.895913563592089\n",
      "GD iter. 8/49: loss=2559390160.4751225, w0=76.87835111477342, w1=13.012673337871481\n",
      "GD iter. 9/49: loss=2191901665.981939, w0=76.16146529223978, w1=13.106081157294996\n",
      "GD iter. 10/49: loss=1956709029.5063012, w0=75.58795663421286, w1=13.180807412833808\n",
      "GD iter. 11/49: loss=1806185742.1618896, w0=75.12914970779133, w1=13.240588417264856\n",
      "GD iter. 12/49: loss=1709850838.2614686, w0=74.7621041666541, w1=13.288413220809694\n",
      "GD iter. 13/49: loss=1648196499.7651978, w0=74.46846773374432, w1=13.326673063645565\n",
      "GD iter. 14/49: loss=1608737723.1275852, w0=74.2335585874165, w1=13.357280937914261\n",
      "GD iter. 15/49: loss=1583484106.0795135, w0=74.04563127035424, w1=13.38176723732922\n",
      "GD iter. 16/49: loss=1567321791.168747, w0=73.89528941670443, w1=13.401356276861184\n",
      "GD iter. 17/49: loss=1556977909.6258566, w0=73.77501593378459, w1=13.417027508486758\n",
      "GD iter. 18/49: loss=1550357825.438407, w0=73.6787971474487, w1=13.429564493787217\n",
      "GD iter. 19/49: loss=1546120971.5584385, w0=73.60182211838, w1=13.439594082027583\n",
      "GD iter. 20/49: loss=1543409385.0752592, w0=73.54024209512504, w1=13.447617752619875\n",
      "GD iter. 21/49: loss=1541673969.7260244, w0=73.49097807652107, w1=13.45403668909371\n",
      "GD iter. 22/49: loss=1540563303.9025142, w0=73.4515668616379, w1=13.459171838272779\n",
      "GD iter. 23/49: loss=1539852477.7754676, w0=73.42003788973136, w1=13.463279957616033\n",
      "GD iter. 24/49: loss=1539397549.054158, w0=73.39481471220613, w1=13.466566453090635\n",
      "GD iter. 25/49: loss=1539106394.6725192, w0=73.37463617018594, w1=13.469195649470318\n",
      "GD iter. 26/49: loss=1538920055.8682706, w0=73.3584933365698, w1=13.471299006574064\n",
      "GD iter. 27/49: loss=1538800799.0335517, w0=73.34557906967687, w1=13.472981692257061\n",
      "GD iter. 28/49: loss=1538724474.6593316, w0=73.33524765616254, w1=13.47432784080346\n",
      "GD iter. 29/49: loss=1538675627.0598307, w0=73.32698252535107, w1=13.475404759640577\n",
      "GD iter. 30/49: loss=1538644364.5961502, w0=73.32037042070189, w1=13.476266294710271\n",
      "GD iter. 31/49: loss=1538624356.6193943, w0=73.31508073698255, w1=13.476955522766026\n",
      "GD iter. 32/49: loss=1538611551.5142708, w0=73.31084899000707, w1=13.47750690521063\n",
      "GD iter. 33/49: loss=1538603356.2469916, w0=73.3074635924267, w1=13.477948011166314\n",
      "GD iter. 34/49: loss=1538598111.275933, w0=73.30475527436239, w1=13.478300895930861\n",
      "GD iter. 35/49: loss=1538594754.4944558, w0=73.30258861991095, w1=13.478583203742499\n",
      "GD iter. 36/49: loss=1538592606.1543097, w0=73.3008552963498, w1=13.478809049991808\n",
      "GD iter. 37/49: loss=1538591231.2166166, w0=73.29946863750088, w1=13.478989726991257\n",
      "GD iter. 38/49: loss=1538590351.2564933, w0=73.29835931042174, w1=13.479134268590816\n",
      "GD iter. 39/49: loss=1538589788.0820138, w0=73.29747184875843, w1=13.479249901870462\n",
      "GD iter. 40/49: loss=1538589427.6503472, w0=73.29676187942779, w1=13.47934240849418\n",
      "GD iter. 41/49: loss=1538589196.9740808, w0=73.29619390396327, w1=13.479416413793153\n",
      "GD iter. 42/49: loss=1538589049.34127, w0=73.29573952359165, w1=13.479475618032332\n",
      "GD iter. 43/49: loss=1538588954.8562715, w0=73.29537601929435, w1=13.479522981423676\n",
      "GD iter. 44/49: loss=1538588894.385872, w0=73.29508521585652, w1=13.47956087213675\n",
      "GD iter. 45/49: loss=1538588855.6848164, w0=73.29485257310625, w1=13.479591184707209\n",
      "GD iter. 46/49: loss=1538588830.9161408, w0=73.29466645890604, w1=13.479615434763577\n",
      "GD iter. 47/49: loss=1538588815.0641887, w0=73.29451756754587, w1=13.479634834808671\n",
      "GD iter. 48/49: loss=1538588804.918939, w0=73.29439845445773, w1=13.479650354844747\n",
      "GD iter. 49/49: loss=1538588798.4259796, w0=73.29430316398722, w1=13.479662770873608\n",
      "GD: execution time=0.011 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.2\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([100, 10])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac52ef0c45f4411dba45f54f6a061e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from just few examples n and their corresponding y_n labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "\n",
    "    return compute_gradient(y, tx, w)\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size):\n",
    "                # Compute the gradient and loss\n",
    "                g = compute_stoch_gradient(minibatch_y, minibatch_tx, w)\n",
    "        \n",
    "                # Update w\n",
    "                w = w - gamma * g   \n",
    "\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                    bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=197165751879.3091, w0=13.426628389266185, w1=-4.643488643260147\n",
      "SGD iter. 1/49: loss=130321459966.93481, w0=26.540107144813774, w1=-6.262076235016409\n",
      "SGD iter. 2/49: loss=98091030209.00433, w0=35.92794129280369, w1=-9.646729445995101\n",
      "SGD iter. 3/49: loss=30780273854.900204, w0=49.90519563030117, w1=7.3314460073506975\n",
      "SGD iter. 4/49: loss=16203427636.958073, w0=56.39277568996655, w1=16.245219682707802\n",
      "SGD iter. 5/49: loss=9759112091.042387, w0=60.74895668151856, w1=10.827484845119027\n",
      "SGD iter. 6/49: loss=8036810333.726059, w0=63.32948216648971, w1=7.94126773460051\n",
      "SGD iter. 7/49: loss=7172717098.930816, w0=64.79274023961558, w1=7.122631746333939\n",
      "SGD iter. 8/49: loss=5367025852.012469, w0=66.46071219941305, w1=8.013819544071524\n",
      "SGD iter. 9/49: loss=5402862950.982948, w0=66.28695003510674, w1=8.170491481242806\n",
      "SGD iter. 10/49: loss=3252328103.1819825, w0=68.4749035136233, w1=10.15528058373226\n",
      "SGD iter. 11/49: loss=3510461905.1086106, w0=67.38292416038828, w1=11.35896566091829\n",
      "SGD iter. 12/49: loss=2270958265.736401, w0=69.47698611126343, w1=13.19973032435832\n",
      "SGD iter. 13/49: loss=1948356201.4966702, w0=70.84323643221134, w1=12.000020396155062\n",
      "SGD iter. 14/49: loss=1946208509.8199623, w0=70.85835954816574, w1=11.989601703633527\n",
      "SGD iter. 15/49: loss=2007999773.8443832, w0=70.72322311492458, w1=11.812461112999097\n",
      "SGD iter. 16/49: loss=1813754396.2268767, w0=72.13731330259834, w1=15.520684875543749\n",
      "SGD iter. 17/49: loss=1546311190.2569368, w0=73.32743387820423, w1=13.08814504405837\n",
      "SGD iter. 18/49: loss=1596275786.1297715, w0=73.9306021036954, w1=12.614623749838389\n",
      "SGD iter. 19/49: loss=1546892870.0091195, w0=72.9935291766847, w1=13.204311249516861\n",
      "SGD iter. 20/49: loss=1563758799.7992883, w0=73.97859055015894, w1=13.665801762014889\n",
      "SGD iter. 21/49: loss=1624983925.7402732, w0=74.52173029224821, w1=13.9491691207469\n",
      "SGD iter. 22/49: loss=2057785961.921878, w0=76.35802528977119, w1=12.48210803278688\n",
      "SGD iter. 23/49: loss=2137386368.172833, w0=73.6219969477511, w1=10.034669843693946\n",
      "SGD iter. 24/49: loss=1801411436.520091, w0=73.01355871257516, w1=11.204223604292022\n",
      "SGD iter. 25/49: loss=1643757844.584706, w0=73.32908512386987, w1=12.0298349543366\n",
      "SGD iter. 26/49: loss=1631526455.0132666, w0=73.48901906070861, w1=12.130382786485455\n",
      "SGD iter. 27/49: loss=1845121022.3354955, w0=75.49780559337232, w1=12.351199331301457\n",
      "SGD iter. 28/49: loss=1613199421.8111186, w0=73.87548432753033, w1=14.55395540574086\n",
      "SGD iter. 29/49: loss=2049852912.4491405, w0=72.37470065539947, w1=16.542442365473374\n",
      "SGD iter. 30/49: loss=1913762766.1218302, w0=73.48647721312189, w1=16.212184223587812\n",
      "SGD iter. 31/49: loss=2016582284.645981, w0=71.1692504992703, w1=11.233462012551207\n",
      "SGD iter. 32/49: loss=2054048651.3481073, w0=70.56796907006081, w1=11.783134142783819\n",
      "SGD iter. 33/49: loss=2336753110.957221, w0=69.71448555002301, w1=11.704629009628144\n",
      "SGD iter. 34/49: loss=2172017455.419842, w0=72.64004610820227, w1=16.978429297798996\n",
      "SGD iter. 35/49: loss=2217122492.2732015, w0=72.18293255174865, w1=16.992030266421974\n",
      "SGD iter. 36/49: loss=1641508477.3374555, w0=74.3251272459419, w1=14.477214091215235\n",
      "SGD iter. 37/49: loss=2078934305.9055192, w0=71.99644136656946, w1=10.459206785124877\n",
      "SGD iter. 38/49: loss=2080365594.8733075, w0=71.83473176091827, w1=10.52906843751456\n",
      "SGD iter. 39/49: loss=1829312713.4777179, w0=73.43696088062342, w1=11.072635699376367\n",
      "SGD iter. 40/49: loss=1697128550.6627727, w0=75.06056550447526, w1=13.256629465826794\n",
      "SGD iter. 41/49: loss=1698027784.298284, w0=75.0648485587171, w1=13.25036754319166\n",
      "SGD iter. 42/49: loss=1634580603.472233, w0=74.67611346539469, w1=13.38284608068849\n",
      "SGD iter. 43/49: loss=1625388397.0617876, w0=73.72459731393755, w1=14.724907592125092\n",
      "SGD iter. 44/49: loss=1624996849.5769064, w0=73.7808687813588, w1=14.700795596798214\n",
      "SGD iter. 45/49: loss=1682461914.6103964, w0=73.40600646488977, w1=15.172313872939348\n",
      "SGD iter. 46/49: loss=1699378122.929855, w0=73.20853742802038, w1=15.270940001616655\n",
      "SGD iter. 47/49: loss=1668058997.719947, w0=71.89121797472416, w1=14.26827164539063\n",
      "SGD iter. 48/49: loss=2108414097.799171, w0=74.11772956465683, w1=16.75352478730971\n",
      "SGD iter. 49/49: loss=1783829809.63149, w0=74.93308668016965, w1=14.968994011171617\n",
      "SGD: execution time=0.037 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.2\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f52ac37cd3c48e1b19e2d1b3f6e962b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=True, add_outlier=True)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((202,), (202, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=197800723.8251788, w0=64.94786659436048, w1=108.40084710012992\n",
      "SGD iter. 1/49: loss=131763322.75174554, w0=16.155115822931506, w1=65.5565612983914\n",
      "SGD iter. 2/49: loss=130956579.35462542, w0=18.403364248161694, w1=67.50098512962474\n",
      "SGD iter. 3/49: loss=214207701.97277272, w0=-22.258943334403405, w1=-21.95971272726699\n",
      "SGD iter. 4/49: loss=169076750.6354875, w0=28.756558599919614, w1=-67.08227960106905\n",
      "SGD iter. 5/49: loss=70690635.08722994, w0=83.6570244938411, w1=-45.895527062833565\n",
      "SGD iter. 6/49: loss=36510077.132255204, w0=38.86916937727876, w1=-9.42796780578275\n",
      "SGD iter. 7/49: loss=2806956.610058678, w0=72.87525705345186, w1=8.961542282429512\n",
      "SGD iter. 8/49: loss=3179797.2643480795, w0=76.67454227080997, w1=6.8875342763288\n",
      "SGD iter. 9/49: loss=4408702.182423348, w0=66.35700675020351, w1=6.0575679143550945\n",
      "SGD iter. 10/49: loss=2747376.7359653907, w0=73.14729170134866, w1=12.432507656723374\n",
      "SGD iter. 11/49: loss=3230787.8268707236, w0=78.67451618240742, w1=13.33123693788077\n",
      "SGD iter. 12/49: loss=2942153.1176178753, w0=75.00412166859162, w1=7.648022209772665\n",
      "SGD iter. 13/49: loss=3579146.971934832, w0=68.07297422668294, w1=13.797450817554349\n",
      "SGD iter. 14/49: loss=3721071.353532863, w0=71.88979439110365, w1=17.80116290898936\n",
      "SGD iter. 15/49: loss=3842113.381491387, w0=72.37865652050547, w1=18.356489144784693\n",
      "SGD iter. 16/49: loss=3874821.452756928, w0=72.29091286313691, w1=18.444672136950953\n",
      "SGD iter. 17/49: loss=3869655.0530999913, w0=72.39909731809239, w1=18.452733477738697\n",
      "SGD iter. 18/49: loss=4338960.134850521, w0=67.36271799223375, w1=17.022683312884155\n",
      "SGD iter. 19/49: loss=4032199.0338194035, w0=68.18318736605659, w1=16.615866483819058\n",
      "SGD iter. 20/49: loss=4874611.393132379, w0=73.51801137445877, w1=21.367579917713197\n",
      "SGD iter. 21/49: loss=4084088.457631439, w0=76.14769404165212, w1=19.03448197706784\n",
      "SGD iter. 22/49: loss=3866241.6784326187, w0=73.34110281622652, w1=18.59224325410326\n",
      "SGD iter. 23/49: loss=3283542.1470783968, w0=69.91687754613145, w1=14.477350924117049\n",
      "SGD iter. 24/49: loss=4207055.612419371, w0=65.45540769897765, w1=10.618796773346736\n",
      "SGD iter. 25/49: loss=4138535.349883648, w0=76.69957364825618, w1=19.03875835607166\n",
      "SGD iter. 26/49: loss=3241322.1420611315, w0=73.63991952415921, w1=16.214491145490154\n",
      "SGD iter. 27/49: loss=5072722.653138387, w0=66.67420744750173, w1=18.915995120074758\n",
      "SGD iter. 28/49: loss=4479845.640617712, w0=76.6552974513182, w1=2.033662938863074\n",
      "SGD iter. 29/49: loss=4360370.894827112, w0=65.76851227182745, w1=7.431704068414929\n",
      "SGD iter. 30/49: loss=5106680.541651248, w0=63.41361146076715, w1=8.814620190536711\n",
      "SGD iter. 31/49: loss=6412664.669632375, w0=60.735313761923344, w1=8.867249490148572\n",
      "SGD iter. 32/49: loss=5692049.415624119, w0=73.87923982315044, w1=23.163277297489124\n",
      "SGD iter. 33/49: loss=5166750.40265783, w0=71.0411953264947, w1=21.6285447990308\n",
      "SGD iter. 34/49: loss=5352540.649428208, w0=64.98706871343748, w1=17.965441410685198\n",
      "SGD iter. 35/49: loss=4424419.606045022, w0=67.65370968144512, w1=17.65758035666051\n",
      "SGD iter. 36/49: loss=4209795.40748708, w0=68.42882239457938, w1=17.5680943629642\n",
      "SGD iter. 37/49: loss=4891454.98005723, w0=65.13938337742445, w1=16.34295585830329\n",
      "SGD iter. 38/49: loss=2823262.1639529355, w0=76.11151392208112, w1=12.565722883499456\n",
      "SGD iter. 39/49: loss=2863698.437592528, w0=76.54362857512886, w1=12.575172407914149\n",
      "SGD iter. 40/49: loss=2758171.4494452453, w0=75.83227559103665, w1=11.500099250158984\n",
      "SGD iter. 41/49: loss=2765030.537178957, w0=75.90447433062106, w1=11.575833226141139\n",
      "SGD iter. 42/49: loss=4644342.901727896, w0=67.41445145798589, w1=18.2121481704401\n",
      "SGD iter. 43/49: loss=4253187.683025845, w0=71.24767579897696, w1=19.320699619611084\n",
      "SGD iter. 44/49: loss=3683551.266487364, w0=80.14477109104983, w1=14.463826336580373\n",
      "SGD iter. 45/49: loss=2754884.4694546023, w0=75.80804513177561, w1=10.660428374770131\n",
      "SGD iter. 46/49: loss=3099042.22090528, w0=69.64445045443422, w1=11.721487249186755\n",
      "SGD iter. 47/49: loss=3149813.185038488, w0=69.41669021117987, w1=11.979952613665354\n",
      "SGD iter. 48/49: loss=3345499.5582289114, w0=68.49888301062622, w1=12.085912544358614\n",
      "SGD iter. 49/49: loss=3068623.259968179, w0=70.19719679352794, w1=9.146803705090553\n",
      "GD: execution time=0.008 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfce128796cb4bed9712a454b44f5341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "\n",
    "    # Start with computing the subgradient for each datapoint\n",
    "    e = y - tx @ w # (N,)\n",
    "    n = e.shape[0]\n",
    "    abs_subgrad = np.zeros((n, 2))\n",
    "    \n",
    "    for i in range(n):\n",
    "        if e[i] > 0:\n",
    "            abs_subgrad[i] = -tx[i] # -X\n",
    "        elif e[i] < 0:\n",
    "            abs_subgrad[i] = tx[i] # X\n",
    "        else:\n",
    "            print(\">>>>>>>> Using subgradient!\")\n",
    "            # For each weight, sample from the range of [-Xi, Xi]\n",
    "            m = tx[i].shape[0]\n",
    "            subgradients = []\n",
    "            for j in range(m):\n",
    "                x = tx[i, j]\n",
    "                g = random.uniform(-x, x)\n",
    "                subgradients.append(g)\n",
    "            abs_subgrad[i] = np.array(subgradients)\n",
    "\n",
    "    # Now, we take the average\n",
    "    return np.mean(abs_subgrad, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters): \n",
    "        # Compute the gradient and loss\n",
    "        g = compute_subgradient_mae(y, tx, w)\n",
    "        loss = compute_loss(y, tx, w, \"MAE\")\n",
    "\n",
    "        # Update w\n",
    "        w = w - gamma * g\n",
    "\n",
    "        # Store weights and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/199: loss=1511131.3750522078, w0=0.9, w1=7.855102706902345e-16\n",
      "SubGD iter. 1/199: loss=1492769.5750522078, w0=1.8, w1=1.571020541380469e-15\n",
      "SubGD iter. 2/199: loss=1474407.775052208, w0=2.7, w1=2.3565308120707034e-15\n",
      "SubGD iter. 3/199: loss=1456045.975052208, w0=3.6, w1=3.142041082760938e-15\n",
      "SubGD iter. 4/199: loss=1437684.175052208, w0=4.5, w1=3.927551353451173e-15\n",
      "SubGD iter. 5/199: loss=1419322.375052208, w0=5.4, w1=4.7130616241414076e-15\n",
      "SubGD iter. 6/199: loss=1400960.575052208, w0=6.300000000000001, w1=5.498571894831642e-15\n",
      "SubGD iter. 7/199: loss=1382598.7750522078, w0=7.200000000000001, w1=6.284082165521877e-15\n",
      "SubGD iter. 8/199: loss=1364236.975052208, w0=8.100000000000001, w1=7.069592436212112e-15\n",
      "SubGD iter. 9/199: loss=1345875.175052208, w0=9.000000000000002, w1=7.855102706902346e-15\n",
      "SubGD iter. 10/199: loss=1327513.3750522078, w0=9.900000000000002, w1=8.64061297759258e-15\n",
      "SubGD iter. 11/199: loss=1309151.575052208, w0=10.800000000000002, w1=9.426123248282814e-15\n",
      "SubGD iter. 12/199: loss=1290789.7750522078, w0=11.700000000000003, w1=1.0211633518973047e-14\n",
      "SubGD iter. 13/199: loss=1272427.975052208, w0=12.600000000000003, w1=1.0997143789663281e-14\n",
      "SubGD iter. 14/199: loss=1254066.1750522077, w0=13.500000000000004, w1=1.1782654060353515e-14\n",
      "SubGD iter. 15/199: loss=1235704.3750522078, w0=14.400000000000004, w1=1.256816433104375e-14\n",
      "SubGD iter. 16/199: loss=1217342.575052208, w0=15.300000000000004, w1=1.3353674601733983e-14\n",
      "SubGD iter. 17/199: loss=1198980.7750522078, w0=16.200000000000003, w1=1.4139184872424217e-14\n",
      "SubGD iter. 18/199: loss=1180618.975052208, w0=17.1, w1=1.4924695143114453e-14\n",
      "SubGD iter. 19/199: loss=1162257.175052208, w0=18.0, w1=1.5710205413804688e-14\n",
      "SubGD iter. 20/199: loss=1143895.375052208, w0=18.9, w1=1.6495715684494924e-14\n",
      "SubGD iter. 21/199: loss=1125533.575052208, w0=19.799999999999997, w1=1.728122595518516e-14\n",
      "SubGD iter. 22/199: loss=1107171.775052208, w0=20.699999999999996, w1=1.8066736225875395e-14\n",
      "SubGD iter. 23/199: loss=1088809.9750522082, w0=21.599999999999994, w1=1.885224649656563e-14\n",
      "SubGD iter. 24/199: loss=1070448.175052208, w0=22.499999999999993, w1=1.9637756767255866e-14\n",
      "SubGD iter. 25/199: loss=1052086.375052208, w0=23.39999999999999, w1=2.04232670379461e-14\n",
      "SubGD iter. 26/199: loss=1033724.5750522082, w0=24.29999999999999, w1=2.1208777308636337e-14\n",
      "SubGD iter. 27/199: loss=1015362.7750522082, w0=25.19999999999999, w1=2.1994287579326572e-14\n",
      "SubGD iter. 28/199: loss=997000.9750522082, w0=26.099999999999987, w1=2.2779797850016808e-14\n",
      "SubGD iter. 29/199: loss=978639.175052208, w0=26.999999999999986, w1=2.3565308120707043e-14\n",
      "SubGD iter. 30/199: loss=960277.3750522083, w0=27.899999999999984, w1=2.435081839139728e-14\n",
      "SubGD iter. 31/199: loss=941915.5750522084, w0=28.799999999999983, w1=2.5136328662087514e-14\n",
      "SubGD iter. 32/199: loss=923553.7750522085, w0=29.69999999999998, w1=2.592183893277775e-14\n",
      "SubGD iter. 33/199: loss=905191.9750522083, w0=30.59999999999998, w1=2.6707349203467985e-14\n",
      "SubGD iter. 34/199: loss=886830.1750522084, w0=31.49999999999998, w1=2.749285947415822e-14\n",
      "SubGD iter. 35/199: loss=868468.3750522084, w0=32.39999999999998, w1=2.8278369744848456e-14\n",
      "SubGD iter. 36/199: loss=850106.5750522084, w0=33.299999999999976, w1=2.906388001553869e-14\n",
      "SubGD iter. 37/199: loss=831744.7750522085, w0=34.199999999999974, w1=2.9849390286228924e-14\n",
      "SubGD iter. 38/199: loss=813382.9750522085, w0=35.09999999999997, w1=3.0634900556919157e-14\n",
      "SubGD iter. 39/199: loss=795021.1750522085, w0=35.99999999999997, w1=3.142041082760939e-14\n",
      "SubGD iter. 40/199: loss=776659.3750522087, w0=36.89999999999997, w1=3.220592109829962e-14\n",
      "SubGD iter. 41/199: loss=758297.5750522087, w0=37.79999999999997, w1=3.2991431368989854e-14\n",
      "SubGD iter. 42/199: loss=739935.7750522086, w0=38.69999999999997, w1=3.3776941639680086e-14\n",
      "SubGD iter. 43/199: loss=721573.9750522086, w0=39.599999999999966, w1=3.456245191037032e-14\n",
      "SubGD iter. 44/199: loss=703212.1750522086, w0=40.499999999999964, w1=3.534796218106055e-14\n",
      "SubGD iter. 45/199: loss=684850.3750522087, w0=41.39999999999996, w1=3.613347245175078e-14\n",
      "SubGD iter. 46/199: loss=666488.5750522087, w0=42.29999999999996, w1=3.6918982722441015e-14\n",
      "SubGD iter. 47/199: loss=648126.7750522088, w0=43.19999999999996, w1=3.770449299313125e-14\n",
      "SubGD iter. 48/199: loss=629764.9750522088, w0=44.09999999999996, w1=3.849000326382148e-14\n",
      "SubGD iter. 49/199: loss=611403.1750522087, w0=44.99999999999996, w1=3.927551353451171e-14\n",
      "SubGD iter. 50/199: loss=593041.3750522088, w0=45.899999999999956, w1=4.0061023805201945e-14\n",
      "SubGD iter. 51/199: loss=574679.5750522088, w0=46.799999999999955, w1=4.084653407589218e-14\n",
      "SubGD iter. 52/199: loss=556409.0588176671, w0=47.691089108910845, w1=0.014332944443479583\n",
      "SubGD iter. 53/199: loss=538495.9562654167, w0=48.573267326732626, w1=0.04253880997271603\n",
      "SubGD iter. 54/199: loss=520871.63140137267, w0=49.43762376237619, w1=0.09664425774410781\n",
      "SubGD iter. 55/199: loss=504061.5705271184, w0=50.28415841584154, w1=0.17646451388749437\n",
      "SubGD iter. 56/199: loss=487672.1408408087, w0=51.130693069306886, w1=0.2562847700308809\n",
      "SubGD iter. 57/199: loss=471546.73857205635, w0=51.95049504950491, w1=0.3735520686019444\n",
      "SubGD iter. 58/199: loss=456091.9406315839, w0=52.76138613861382, w1=0.5015127874603322\n",
      "SubGD iter. 59/199: loss=440998.49330933316, w0=53.545544554455404, w1=0.662192752923334\n",
      "SubGD iter. 60/199: loss=426536.79977203533, w0=54.31188118811877, w1=0.8422783308914241\n",
      "SubGD iter. 61/199: loss=412488.8292213358, w0=55.07821782178213, w1=1.0223639088595142\n",
      "SubGD iter. 62/199: loss=398592.83518521866, w0=55.82673267326728, w1=1.2207501560956762\n",
      "SubGD iter. 63/199: loss=385271.071812389, w0=56.530693069306885, w1=1.4580721175542803\n",
      "SubGD iter. 64/199: loss=372912.0445686074, w0=57.21683168316827, w1=1.7089720470374954\n",
      "SubGD iter. 65/199: loss=360901.38605291443, w0=57.86732673267322, w1=1.9914995551971482\n",
      "SubGD iter. 66/199: loss=349566.3753619445, w0=58.50891089108906, w1=2.275553267488901\n",
      "SubGD iter. 67/199: loss=338512.84895452636, w0=59.12376237623757, w1=2.576874828006045\n",
      "SubGD iter. 68/199: loss=327921.62099106156, w0=59.72970297029698, w1=2.8883085866850235\n",
      "SubGD iter. 69/199: loss=317630.6199703816, w0=60.28217821782173, w1=3.2338009525404248\n",
      "SubGD iter. 70/199: loss=308141.8040494938, w0=60.81683168316827, w1=3.5880896940575067\n",
      "SubGD iter. 71/199: loss=298880.676527814, w0=61.342574257425696, w1=3.9472830427357666\n",
      "SubGD iter. 72/199: loss=289709.35239061434, w0=61.859405940594016, w1=4.313184472491707\n",
      "SubGD iter. 73/199: loss=280680.6525929727, w0=62.35841584158411, w1=4.68886772489613\n",
      "SubGD iter. 74/199: loss=271944.492990276, w0=62.83960396039599, w1=5.066599812522915\n",
      "SubGD iter. 75/199: loss=263513.86706245964, w0=63.30297029702965, w1=5.456656115188901\n",
      "SubGD iter. 76/199: loss=255197.73346187358, w0=63.766336633663315, w1=5.846712417854887\n",
      "SubGD iter. 77/199: loss=246922.26473040142, w0=64.21188118811877, w1=6.243471933808226\n",
      "SubGD iter. 78/199: loss=238880.94713928286, w0=64.6485148514851, w1=6.647143964828447\n",
      "SubGD iter. 79/199: loss=230865.22656347376, w0=65.08514851485144, w1=7.0508159958486685\n",
      "SubGD iter. 80/199: loss=222849.50598766454, w0=65.52178217821778, w1=7.45448802686889\n",
      "SubGD iter. 81/199: loss=215009.4303679587, w0=65.92277227722768, w1=7.86774633185831\n",
      "SubGD iter. 82/199: loss=207518.04496833272, w0=66.31485148514847, w1=8.28660180183467\n",
      "SubGD iter. 83/199: loss=200081.71374782769, w0=66.68910891089104, w1=8.715418523566079\n",
      "SubGD iter. 84/199: loss=192742.3210604594, w0=67.0544554455445, w1=9.145769249488875\n",
      "SubGD iter. 85/199: loss=185556.17318710135, w0=67.41089108910886, w1=9.57280114939691\n",
      "SubGD iter. 86/199: loss=178542.35976411912, w0=67.76732673267321, w1=9.999833049304943\n",
      "SubGD iter. 87/199: loss=171632.46522783578, w0=68.10594059405935, w1=10.416628066390683\n",
      "SubGD iter. 88/199: loss=165324.5615384147, w0=68.44455445544548, w1=10.797800719768928\n",
      "SubGD iter. 89/199: loss=159540.9539896318, w0=68.78316831683162, w1=11.161281753509614\n",
      "SubGD iter. 90/199: loss=153958.37294259365, w0=69.11287128712866, w1=11.519371172996431\n",
      "SubGD iter. 91/199: loss=148606.55317994035, w0=69.42475247524747, w1=11.88426466519213\n",
      "SubGD iter. 92/199: loss=143572.23159926105, w0=69.71881188118807, w1=12.234891257921985\n",
      "SubGD iter. 93/199: loss=138974.2018739592, w0=70.00396039603956, w1=12.573463804887085\n",
      "SubGD iter. 94/199: loss=134597.94717745352, w0=70.29801980198016, w1=12.878416633692547\n",
      "SubGD iter. 95/199: loss=130546.4431347095, w0=70.58316831683165, w1=13.188082917681543\n",
      "SubGD iter. 96/199: loss=126580.87572578393, w0=70.85940594059402, w1=13.49322975711924\n",
      "SubGD iter. 97/199: loss=122931.15685917973, w0=71.10891089108907, w1=13.77292728107376\n",
      "SubGD iter. 98/199: loss=119768.7829558551, w0=71.349504950495, w1=14.043702024297145\n",
      "SubGD iter. 99/199: loss=116838.57247926807, w0=71.57227722772272, w1=14.300947118283876\n",
      "SubGD iter. 100/199: loss=114408.24063339258, w0=71.74158415841579, w1=14.51580353731991\n",
      "SubGD iter. 101/199: loss=112743.21693650301, w0=71.89306930693064, w1=14.713676351520892\n",
      "SubGD iter. 102/199: loss=111615.22414361616, w0=71.99999999999994, w1=14.85444312894561\n",
      "SubGD iter. 103/199: loss=110921.35612692068, w0=72.09801980198014, w1=14.991537381078931\n",
      "SubGD iter. 104/199: loss=110322.4391806522, w0=72.18712871287123, w1=15.115164535954193\n",
      "SubGD iter. 105/199: loss=109812.33040750246, w0=72.2584158415841, w1=15.219948193554048\n",
      "SubGD iter. 106/199: loss=109449.38088536363, w0=72.32079207920786, w1=15.316850379352626\n",
      "SubGD iter. 107/199: loss=109148.31925673796, w0=72.38316831683163, w1=15.413752565151205\n",
      "SubGD iter. 108/199: loss=108870.33064617241, w0=72.43663366336628, w1=15.499946530986527\n",
      "SubGD iter. 109/199: loss=108700.0211493665, w0=72.48118811881183, w1=15.55255644061696\n",
      "SubGD iter. 110/199: loss=108596.69214209405, w0=72.50792079207916, w1=15.604857165591518\n",
      "SubGD iter. 111/199: loss=108531.80131695389, w0=72.5346534653465, w1=15.639435840069758\n",
      "SubGD iter. 112/199: loss=108492.57928691502, w0=72.56138613861383, w1=15.655814807731435\n",
      "SubGD iter. 113/199: loss=108470.29789090717, w0=72.58811881188116, w1=15.672193775393112\n",
      "SubGD iter. 114/199: loss=108448.5006844611, w0=72.60594059405938, w1=15.700050381498514\n",
      "SubGD iter. 115/199: loss=108426.87353210327, w0=72.63267326732671, w1=15.71642934916019\n",
      "SubGD iter. 116/199: loss=108404.59213609541, w0=72.65940594059404, w1=15.732808316821867\n",
      "SubGD iter. 117/199: loss=108384.88588943293, w0=72.66831683168316, w1=15.747119189135715\n",
      "SubGD iter. 118/199: loss=108378.44327681478, w0=72.67722772277227, w1=15.761430061449563\n",
      "SubGD iter. 119/199: loss=108372.00066419662, w0=72.68613861386139, w1=15.77574093376341\n",
      "SubGD iter. 120/199: loss=108368.34962002563, w0=72.68613861386139, w1=15.780822411861237\n",
      "SubGD iter. 121/199: loss=108367.76427713246, w0=72.68613861386139, w1=15.785903889959064\n",
      "SubGD iter. 122/199: loss=108367.17893423923, w0=72.68613861386139, w1=15.79098536805689\n",
      "SubGD iter. 123/199: loss=108366.59359134606, w0=72.68613861386139, w1=15.796066846154718\n",
      "SubGD iter. 124/199: loss=108366.00824845285, w0=72.68613861386139, w1=15.801148324252544\n",
      "SubGD iter. 125/199: loss=108365.42290555965, w0=72.68613861386139, w1=15.806229802350371\n",
      "SubGD iter. 126/199: loss=108364.83756266643, w0=72.68613861386139, w1=15.811311280448198\n",
      "SubGD iter. 127/199: loss=108364.25221977325, w0=72.68613861386139, w1=15.816392758546025\n",
      "SubGD iter. 128/199: loss=108363.66687688007, w0=72.68613861386139, w1=15.821474236643851\n",
      "SubGD iter. 129/199: loss=108363.08153398687, w0=72.68613861386139, w1=15.826555714741678\n",
      "SubGD iter. 130/199: loss=108362.49619109367, w0=72.68613861386139, w1=15.831637192839505\n",
      "SubGD iter. 131/199: loss=108361.91084820047, w0=72.68613861386139, w1=15.836718670937332\n",
      "SubGD iter. 132/199: loss=108361.32550530726, w0=72.68613861386139, w1=15.841800149035159\n",
      "SubGD iter. 133/199: loss=108360.74016241406, w0=72.68613861386139, w1=15.846881627132985\n",
      "SubGD iter. 134/199: loss=108360.15481952089, w0=72.68613861386139, w1=15.851963105230812\n",
      "SubGD iter. 135/199: loss=108359.56947662767, w0=72.68613861386139, w1=15.857044583328639\n",
      "SubGD iter. 136/199: loss=108358.98413373447, w0=72.68613861386139, w1=15.862126061426466\n",
      "SubGD iter. 137/199: loss=108358.39879084128, w0=72.68613861386139, w1=15.867207539524292\n",
      "SubGD iter. 138/199: loss=108357.81344794811, w0=72.68613861386139, w1=15.87228901762212\n",
      "SubGD iter. 139/199: loss=108357.2281050549, w0=72.68613861386139, w1=15.877370495719946\n",
      "SubGD iter. 140/199: loss=108356.6427621617, w0=72.68613861386139, w1=15.882451973817773\n",
      "SubGD iter. 141/199: loss=108356.0574192685, w0=72.68613861386139, w1=15.8875334519156\n",
      "SubGD iter. 142/199: loss=108355.4720763753, w0=72.68613861386139, w1=15.892614930013426\n",
      "SubGD iter. 143/199: loss=108354.88673348211, w0=72.68613861386139, w1=15.897696408111253\n",
      "SubGD iter. 144/199: loss=108354.30139058891, w0=72.68613861386139, w1=15.90277788620908\n",
      "SubGD iter. 145/199: loss=108353.7160476957, w0=72.68613861386139, w1=15.907859364306907\n",
      "SubGD iter. 146/199: loss=108353.7643829455, w0=72.67722772277227, w1=15.90512580743953\n",
      "SubGD iter. 147/199: loss=108353.4455872156, w0=72.67722772277227, w1=15.910207285537357\n",
      "SubGD iter. 148/199: loss=108352.86024432241, w0=72.67722772277227, w1=15.915288763635184\n",
      "SubGD iter. 149/199: loss=108352.42475828182, w0=72.66831683168316, w1=15.912555206767808\n",
      "SubGD iter. 150/199: loss=108352.58978384228, w0=72.66831683168316, w1=15.917636684865634\n",
      "SubGD iter. 151/199: loss=108352.00444094912, w0=72.66831683168316, w1=15.922718162963461\n",
      "SubGD iter. 152/199: loss=108351.41909805592, w0=72.66831683168316, w1=15.927799641061288\n",
      "SubGD iter. 153/199: loss=108351.4000160312, w0=72.65940594059404, w1=15.925066084193912\n",
      "SubGD iter. 154/199: loss=108351.14863757578, w0=72.65940594059404, w1=15.930147562291738\n",
      "SubGD iter. 155/199: loss=108350.56329468258, w0=72.65940594059404, w1=15.935229040389565\n",
      "SubGD iter. 156/199: loss=108350.06039136753, w0=72.65049504950493, w1=15.932495483522189\n",
      "SubGD iter. 157/199: loss=108350.2928342025, w0=72.65049504950493, w1=15.937576961620016\n",
      "SubGD iter. 158/199: loss=108349.7074913093, w0=72.65049504950493, w1=15.942658439717842\n",
      "SubGD iter. 159/199: loss=108349.12214841609, w0=72.65049504950493, w1=15.94773991781567\n",
      "SubGD iter. 160/199: loss=108349.03564911691, w0=72.64158415841581, w1=15.945006360948293\n",
      "SubGD iter. 161/199: loss=108348.85168793598, w0=72.64158415841581, w1=15.95008783904612\n",
      "SubGD iter. 162/199: loss=108348.26634504278, w0=72.64158415841581, w1=15.955169317143946\n",
      "SubGD iter. 163/199: loss=108347.69602445322, w0=72.6326732673267, w1=15.95243576027657\n",
      "SubGD iter. 164/199: loss=108347.99588456267, w0=72.6326732673267, w1=15.957517238374397\n",
      "SubGD iter. 165/199: loss=108347.41054166947, w0=72.6326732673267, w1=15.962598716472224\n",
      "SubGD iter. 166/199: loss=108346.82519877626, w0=72.6326732673267, w1=15.96768019457005\n",
      "SubGD iter. 167/199: loss=108346.6712822026, w0=72.62376237623758, w1=15.964946637702674\n",
      "SubGD iter. 168/199: loss=108347.86287143647, w0=72.6326732673267, w1=15.970692108883622\n",
      "SubGD iter. 169/199: loss=108346.85792058396, w0=72.62376237623758, w1=15.967958552016245\n",
      "SubGD iter. 170/199: loss=108347.47058933176, w0=72.6326732673267, w1=15.973704023197193\n",
      "SubGD iter. 171/199: loss=108347.04455896531, w0=72.62376237623758, w1=15.970970466329817\n",
      "SubGD iter. 172/199: loss=108347.07830722704, w0=72.6326732673267, w1=15.976715937510765\n",
      "SubGD iter. 173/199: loss=108347.23119734666, w0=72.62376237623758, w1=15.973982380643388\n",
      "SubGD iter. 174/199: loss=108346.6860251223, w0=72.6326732673267, w1=15.979727851824336\n",
      "SubGD iter. 175/199: loss=108347.41783572802, w0=72.62376237623758, w1=15.97699429495696\n",
      "SubGD iter. 176/199: loss=108346.5752382171, w0=72.62376237623758, w1=15.974924731172706\n",
      "SubGD iter. 177/199: loss=108346.56329014032, w0=72.6326732673267, w1=15.980670202353654\n",
      "SubGD iter. 178/199: loss=108347.47623007765, w0=72.62376237623758, w1=15.977936645486277\n",
      "SubGD iter. 179/199: loss=108346.61944832026, w0=72.62376237623758, w1=15.975867081702024\n",
      "SubGD iter. 180/199: loss=108346.52235533246, w0=72.62376237623758, w1=15.97379751791777\n",
      "SubGD iter. 181/199: loss=108346.71010228105, w0=72.6326732673267, w1=15.979542989098718\n",
      "SubGD iter. 182/199: loss=108347.40638039555, w0=72.62376237623758, w1=15.976809432231342\n",
      "SubGD iter. 183/199: loss=108346.56656543566, w0=72.62376237623758, w1=15.974739868447088\n",
      "SubGD iter. 184/199: loss=108346.58736729906, w0=72.6326732673267, w1=15.980485339628036\n",
      "SubGD iter. 185/199: loss=108347.46477474515, w0=72.62376237623758, w1=15.97775178276066\n",
      "SubGD iter. 186/199: loss=108346.61077553884, w0=72.62376237623758, w1=15.975682218976406\n",
      "SubGD iter. 187/199: loss=108346.51368255104, w0=72.62376237623758, w1=15.973612655192152\n",
      "SubGD iter. 188/199: loss=108346.7341794398, w0=72.6326732673267, w1=15.9793581263731\n",
      "SubGD iter. 189/199: loss=108347.39492506305, w0=72.62376237623758, w1=15.976624569505724\n",
      "SubGD iter. 190/199: loss=108346.55789265421, w0=72.62376237623758, w1=15.97455500572147\n",
      "SubGD iter. 191/199: loss=108346.61144445784, w0=72.6326732673267, w1=15.980300476902418\n",
      "SubGD iter. 192/199: loss=108347.45331941267, w0=72.62376237623758, w1=15.977566920035041\n",
      "SubGD iter. 193/199: loss=108346.6021027574, w0=72.62376237623758, w1=15.975497356250788\n",
      "SubGD iter. 194/199: loss=108346.5050097696, w0=72.62376237623758, w1=15.973427792466534\n",
      "SubGD iter. 195/199: loss=108346.75825659858, w0=72.6326732673267, w1=15.979173263647482\n",
      "SubGD iter. 196/199: loss=108347.38346973057, w0=72.62376237623758, w1=15.976439706780106\n",
      "SubGD iter. 197/199: loss=108346.5492198728, w0=72.62376237623758, w1=15.974370142995852\n",
      "SubGD iter. 198/199: loss=108346.63552161658, w0=72.6326732673267, w1=15.9801156141768\n",
      "SubGD iter. 199/199: loss=108347.44186408017, w0=72.62376237623758, w1=15.977382057309423\n",
      "SubGD: execution time=0.067 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 200\n",
    "gamma = 0.9\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9bb001e9fc84311a90fbeb5c929f627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=201, min=1), Output()), _dom_classes=('widg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic SubGradient Descent algorithm (SubSGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size):\n",
    "                # Compute the gradient and loss\n",
    "                g = compute_subgradient_mae(minibatch_y, minibatch_tx, w)\n",
    "        \n",
    "                # Update w\n",
    "                w = w - gamma * g\n",
    "        \n",
    "        loss = compute_loss(y, tx, w, \"MAE\")\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/499: loss=1496849.975052208, w0=0.7, w1=0.7951697251173472\n",
      "SubSGD iter. 1/499: loss=1482568.575052208, w0=1.4, w1=1.7420819868597777\n",
      "SubSGD iter. 2/499: loss=1468287.175052208, w0=2.0999999999999996, w1=0.5580797864658862\n",
      "SubSGD iter. 3/499: loss=1454005.7750522078, w0=2.8, w1=0.18781169593708957\n",
      "SubSGD iter. 4/499: loss=1439724.3750522078, w0=3.5, w1=-0.2439808823463308\n",
      "SubSGD iter. 5/499: loss=1425442.975052208, w0=4.2, w1=0.8139344244812274\n",
      "SubSGD iter. 6/499: loss=1411161.5750522078, w0=4.9, w1=1.012695290299752\n",
      "SubSGD iter. 7/499: loss=1396880.175052208, w0=5.6000000000000005, w1=0.7572634091981811\n",
      "SubSGD iter. 8/499: loss=1382598.7750522078, w0=6.300000000000001, w1=1.4001931079619767\n",
      "SubSGD iter. 9/499: loss=1368317.3750522078, w0=7.000000000000001, w1=2.256415160466515\n",
      "SubSGD iter. 10/499: loss=1354035.975052208, w0=7.700000000000001, w1=2.072254382148195\n",
      "SubSGD iter. 11/499: loss=1339754.5750522078, w0=8.4, w1=3.030389473050002\n",
      "SubSGD iter. 12/499: loss=1325473.175052208, w0=9.1, w1=4.570451811437188\n",
      "SubSGD iter. 13/499: loss=1311191.7750522078, w0=9.799999999999999, w1=4.130256556730217\n",
      "SubSGD iter. 14/499: loss=1296910.3750522078, w0=10.499999999999998, w1=3.092742362916676\n",
      "SubSGD iter. 15/499: loss=1282628.9750522082, w0=11.199999999999998, w1=3.011928057427965\n",
      "SubSGD iter. 16/499: loss=1268347.5750522083, w0=11.899999999999997, w1=1.9744138636144246\n",
      "SubSGD iter. 17/499: loss=1254066.175052208, w0=12.599999999999996, w1=2.7203995172018214\n",
      "SubSGD iter. 18/499: loss=1239784.7750522082, w0=13.299999999999995, w1=3.335060498332208\n",
      "SubSGD iter. 19/499: loss=1225503.375052208, w0=13.999999999999995, w1=3.8442463422784603\n",
      "SubSGD iter. 20/499: loss=1211221.975052208, w0=14.699999999999994, w1=3.060013614239136\n",
      "SubSGD iter. 21/499: loss=1196940.5750522083, w0=15.399999999999993, w1=3.2383657356189506\n",
      "SubSGD iter. 22/499: loss=1182659.175052208, w0=16.099999999999994, w1=3.8618538579051283\n",
      "SubSGD iter. 23/499: loss=1168377.775052208, w0=16.799999999999994, w1=3.4797278733547934\n",
      "SubSGD iter. 24/499: loss=1154096.3750522078, w0=17.499999999999993, w1=3.0539417260640542\n",
      "SubSGD iter. 25/499: loss=1139814.975052208, w0=18.199999999999992, w1=2.0270095284715204\n",
      "SubSGD iter. 26/499: loss=1125533.5750522083, w0=18.89999999999999, w1=3.0834107598504104\n",
      "SubSGD iter. 27/499: loss=1111252.1750522081, w0=19.59999999999999, w1=2.574909642110577\n",
      "SubSGD iter. 28/499: loss=1096970.7750522082, w0=20.29999999999999, w1=1.8943104644544944\n",
      "SubSGD iter. 29/499: loss=1082689.375052208, w0=20.99999999999999, w1=2.3608925904210696\n",
      "SubSGD iter. 30/499: loss=1068407.9750522084, w0=21.69999999999999, w1=2.6104910531082477\n",
      "SubSGD iter. 31/499: loss=1054126.5750522083, w0=22.399999999999988, w1=2.2573753015409332\n",
      "SubSGD iter. 32/499: loss=1039845.1750522082, w0=23.099999999999987, w1=1.4575445674782237\n",
      "SubSGD iter. 33/499: loss=1025563.7750522082, w0=23.799999999999986, w1=1.121181609802147\n",
      "SubSGD iter. 34/499: loss=1011282.3750522083, w0=24.499999999999986, w1=1.7341741069857068\n",
      "SubSGD iter. 35/499: loss=997000.9750522083, w0=25.199999999999985, w1=0.5227512190595267\n",
      "SubSGD iter. 36/499: loss=982719.5750522082, w0=25.899999999999984, w1=0.33859044074120676\n",
      "SubSGD iter. 37/499: loss=968438.1750522084, w0=26.599999999999984, w1=-0.03699539754536296\n",
      "SubSGD iter. 38/499: loss=954156.7750522082, w0=27.299999999999983, w1=1.046879999145939\n",
      "SubSGD iter. 39/499: loss=939875.3750522084, w0=27.999999999999982, w1=0.7914481180443682\n",
      "SubSGD iter. 40/499: loss=925593.9750522083, w0=28.69999999999998, w1=0.6644336728163431\n",
      "SubSGD iter. 41/499: loss=911312.5750522082, w0=29.39999999999998, w1=1.5696087760034065\n",
      "SubSGD iter. 42/499: loss=897031.1750522082, w0=30.09999999999998, w1=2.934978228667018\n",
      "SubSGD iter. 43/499: loss=882749.7750522085, w0=30.79999999999998, w1=4.053288449278499\n",
      "SubSGD iter. 44/499: loss=868468.3750522084, w0=31.49999999999998, w1=3.86982267022808\n",
      "SubSGD iter. 45/499: loss=854186.9750522083, w0=32.19999999999998, w1=3.9801227036888713\n",
      "SubSGD iter. 46/499: loss=839905.5750522082, w0=32.899999999999984, w1=4.446704829655446\n",
      "SubSGD iter. 47/499: loss=825624.175052208, w0=33.59999999999999, w1=5.503106061034336\n",
      "SubSGD iter. 48/499: loss=811342.775052208, w0=34.29999999999999, w1=5.668912320601833\n",
      "SubSGD iter. 49/499: loss=797061.3750522081, w0=34.99999999999999, w1=6.196968136112481\n",
      "SubSGD iter. 50/499: loss=782779.9750522078, w0=35.699999999999996, w1=6.183212940136991\n",
      "SubSGD iter. 51/499: loss=768498.5750522078, w0=36.4, w1=6.379733022915493\n",
      "SubSGD iter. 52/499: loss=754217.1750522078, w0=37.1, w1=7.7424844183072405\n",
      "SubSGD iter. 53/499: loss=739935.7750522076, w0=37.800000000000004, w1=7.199467956942142\n",
      "SubSGD iter. 54/499: loss=725654.3750522077, w0=38.50000000000001, w1=6.849530025461824\n",
      "SubSGD iter. 55/499: loss=711372.9750522076, w0=39.20000000000001, w1=6.245763955495311\n",
      "SubSGD iter. 56/499: loss=697091.5750522076, w0=39.90000000000001, w1=5.8199778082045714\n",
      "SubSGD iter. 57/499: loss=682810.1750522077, w0=40.600000000000016, w1=5.2500176836685855\n",
      "SubSGD iter. 58/499: loss=668528.7750522075, w0=41.30000000000002, w1=4.970088691232123\n",
      "SubSGD iter. 59/499: loss=654247.3750522074, w0=42.00000000000002, w1=4.397078608217499\n",
      "SubSGD iter. 60/499: loss=639965.9750522074, w0=42.700000000000024, w1=5.192248333334846\n",
      "SubSGD iter. 61/499: loss=625684.5750522075, w0=43.40000000000003, w1=4.826327602604449\n",
      "SubSGD iter. 62/499: loss=611403.1750522073, w0=44.10000000000003, w1=4.9917803945370745\n",
      "SubSGD iter. 63/499: loss=597121.7750522072, w0=44.80000000000003, w1=5.6109137904817405\n",
      "SubSGD iter. 64/499: loss=582840.375052207, w0=45.500000000000036, w1=5.585616025092899\n",
      "SubSGD iter. 65/499: loss=568558.975052207, w0=46.20000000000004, w1=6.9483674204846455\n",
      "SubSGD iter. 66/499: loss=554277.5750522071, w0=46.90000000000004, w1=7.7097243711037144\n",
      "SubSGD iter. 67/499: loss=539996.175052207, w0=47.600000000000044, w1=7.609447271863505\n",
      "SubSGD iter. 68/499: loss=525714.7750522068, w0=48.30000000000005, w1=7.6247549385756415\n",
      "SubSGD iter. 69/499: loss=511433.3750522067, w0=49.00000000000005, w1=7.667081495179132\n",
      "SubSGD iter. 70/499: loss=497151.97505220666, w0=49.70000000000005, w1=8.299355923660823\n",
      "SubSGD iter. 71/499: loss=482870.5750522067, w0=50.400000000000055, w1=7.565241600659833\n",
      "SubSGD iter. 72/499: loss=468589.1750522066, w0=51.10000000000006, w1=7.142002175887319\n",
      "SubSGD iter. 73/499: loss=454307.7750522066, w0=51.80000000000006, w1=7.320354297267133\n",
      "SubSGD iter. 74/499: loss=440026.37505220645, w0=52.500000000000064, w1=8.488685097784602\n",
      "SubSGD iter. 75/499: loss=425744.9750522065, w0=53.20000000000007, w1=9.44682018868641\n",
      "SubSGD iter. 76/499: loss=411463.5750522064, w0=53.90000000000007, w1=8.876860064150424\n",
      "SubSGD iter. 77/499: loss=397182.17505220626, w0=54.60000000000007, w1=8.990680390964737\n",
      "SubSGD iter. 78/499: loss=382900.7750522062, w0=55.300000000000075, w1=8.466047466252999\n",
      "SubSGD iter. 79/499: loss=368619.37505220616, w0=56.00000000000008, w1=8.995748440315115\n",
      "SubSGD iter. 80/499: loss=354337.9750522061, w0=56.70000000000008, w1=8.875856626826783\n",
      "SubSGD iter. 81/499: loss=340056.57505220606, w0=57.400000000000084, w1=9.933771933654342\n",
      "SubSGD iter. 82/499: loss=325844.0521512268, w0=58.10000000000009, w1=9.567851202923944\n",
      "SubSGD iter. 83/499: loss=311671.487556955, w0=58.80000000000009, w1=9.73365746249144\n",
      "SubSGD iter. 84/499: loss=297602.4331053027, w0=59.50000000000009, w1=9.983255925178618\n",
      "SubSGD iter. 85/499: loss=283633.9802454044, w0=60.200000000000095, w1=10.36179570853535\n",
      "SubSGD iter. 86/499: loss=269714.56416877, w0=60.9000000000001, w1=10.626580817726119\n",
      "SubSGD iter. 87/499: loss=256296.93916421093, w0=61.6000000000001, w1=10.186385563019147\n",
      "SubSGD iter. 88/499: loss=243150.07516980366, w0=62.300000000000104, w1=10.351838354951774\n",
      "SubSGD iter. 89/499: loss=228904.92961537594, w0=63.00000000000011, w1=11.717207807615384\n",
      "SubSGD iter. 90/499: loss=215774.08758404467, w0=63.70000000000011, w1=11.946329499902143\n",
      "SubSGD iter. 91/499: loss=202439.99494188058, w0=64.4000000000001, w1=12.499535415978256\n",
      "SubSGD iter. 92/499: loss=190283.58248964933, w0=65.10000000000011, w1=12.418721110489544\n",
      "SubSGD iter. 93/499: loss=179340.1657611003, w0=65.80000000000011, w1=12.213887590614322\n",
      "SubSGD iter. 94/499: loss=170041.23417804207, w0=66.50000000000011, w1=12.18992175081123\n",
      "SubSGD iter. 95/499: loss=162618.21815991218, w0=67.20000000000012, w1=12.07974763393049\n",
      "SubSGD iter. 96/499: loss=152698.87545747255, w0=67.90000000000012, w1=12.503288886984505\n",
      "SubSGD iter. 97/499: loss=138939.34120447197, w0=68.60000000000012, w1=13.868658339648116\n",
      "SubSGD iter. 98/499: loss=144457.15535582622, w0=67.90000000000012, w1=14.71007684937406\n",
      "SubSGD iter. 99/499: loss=153498.88255216155, w0=67.20000000000012, w1=14.992624668460286\n",
      "SubSGD iter. 100/499: loss=143688.2903722783, w0=67.90000000000012, w1=15.281121933017701\n",
      "SubSGD iter. 101/499: loss=136147.4494578468, w0=68.60000000000012, w1=14.660070359447108\n",
      "SubSGD iter. 102/499: loss=126860.73301592287, w0=69.30000000000013, w1=15.30621759283433\n",
      "SubSGD iter. 103/499: loss=120163.80091733094, w0=70.00000000000013, w1=16.487022293534224\n",
      "SubSGD iter. 104/499: loss=114745.25659819359, w0=70.70000000000013, w1=15.633176023108955\n",
      "SubSGD iter. 105/499: loss=112672.65992081285, w0=71.40000000000013, w1=14.838806678618175\n",
      "SubSGD iter. 106/499: loss=115220.04573246499, w0=70.70000000000013, w1=15.269817363366789\n",
      "SubSGD iter. 107/499: loss=110918.55281960024, w0=71.40000000000013, w1=15.921874260809243\n",
      "SubSGD iter. 108/499: loss=109537.74734787027, w0=72.10000000000014, w1=15.30273310539486\n",
      "SubSGD iter. 109/499: loss=111887.18325373885, w0=71.40000000000013, w1=15.170409579041022\n",
      "SubSGD iter. 110/499: loss=116397.54857367728, w0=70.70000000000013, w1=14.909697357659159\n",
      "SubSGD iter. 111/499: loss=111191.77992210216, w0=71.40000000000013, w1=15.552627056422955\n",
      "SubSGD iter. 112/499: loss=108951.2338224468, w0=72.10000000000014, w1=16.184901484904646\n",
      "SubSGD iter. 113/499: loss=108644.02573307439, w0=72.80000000000014, w1=16.455039935194318\n",
      "SubSGD iter. 114/499: loss=109383.78121065874, w0=72.10000000000014, w1=15.398638703815427\n",
      "SubSGD iter. 115/499: loss=110963.23177424801, w0=71.40000000000013, w1=15.809713888357653\n",
      "SubSGD iter. 116/499: loss=124720.22665472739, w0=72.10000000000014, w1=12.436570210767975\n",
      "SubSGD iter. 117/499: loss=119528.84877960727, w0=72.80000000000014, w1=12.864087295985394\n",
      "SubSGD iter. 118/499: loss=118681.81804890411, w0=72.10000000000014, w1=13.239673134271964\n",
      "SubSGD iter. 119/499: loss=112010.94232007102, w0=72.80000000000014, w1=14.118921100168135\n",
      "SubSGD iter. 120/499: loss=111643.07872825048, w0=72.10000000000014, w1=14.550713678451556\n",
      "SubSGD iter. 121/499: loss=112210.72071996775, w0=71.40000000000013, w1=15.02876188087768\n",
      "SubSGD iter. 122/499: loss=114932.37834771037, w0=70.70000000000013, w1=15.468450285962865\n",
      "SubSGD iter. 123/499: loss=111795.81101046648, w0=71.40000000000013, w1=15.213018404861295\n",
      "SubSGD iter. 124/499: loss=115488.59228701386, w0=70.70000000000013, w1=15.15670878981599\n",
      "SubSGD iter. 125/499: loss=119992.24617448251, w0=70.00000000000013, w1=15.436637782252454\n",
      "SubSGD iter. 126/499: loss=126404.47822118975, w0=69.30000000000013, w1=15.71918560133868\n",
      "SubSGD iter. 127/499: loss=119635.31575302713, w0=70.00000000000013, w1=16.169365347544975\n",
      "SubSGD iter. 128/499: loss=126301.95888740823, w0=69.30000000000013, w1=16.11305573249967\n",
      "SubSGD iter. 129/499: loss=119429.84285275843, w0=70.00000000000013, w1=15.8576238513981\n",
      "SubSGD iter. 130/499: loss=114973.96875422377, w0=70.70000000000013, w1=15.43183770410736\n",
      "SubSGD iter. 131/499: loss=110872.42028774154, w0=71.40000000000013, w1=16.156857894188164\n",
      "SubSGD iter. 132/499: loss=109073.26251803368, w0=72.10000000000014, w1=16.353202487705392\n",
      "SubSGD iter. 133/499: loss=111011.60463546003, w0=71.40000000000013, w1=15.747799336261407\n",
      "SubSGD iter. 134/499: loss=110725.83805309446, w0=72.10000000000014, w1=14.84616707184865\n",
      "SubSGD iter. 135/499: loss=111320.7154094558, w0=71.40000000000013, w1=15.467218645419242\n",
      "SubSGD iter. 136/499: loss=114588.9476272524, w0=70.70000000000013, w1=15.817555578787633\n",
      "SubSGD iter. 137/499: loss=110996.72689555783, w0=71.40000000000013, w1=16.370761494863746\n",
      "SubSGD iter. 138/499: loss=111924.2480754572, w0=72.10000000000014, w1=17.49589145499405\n",
      "SubSGD iter. 139/499: loss=109916.64465545365, w0=72.80000000000014, w1=16.941784380997472\n",
      "SubSGD iter. 140/499: loss=110558.24118111825, w0=73.50000000000014, w1=16.758318601947053\n",
      "SubSGD iter. 141/499: loss=108402.9874869412, w0=72.80000000000014, w1=16.0573846045123\n",
      "SubSGD iter. 142/499: loss=110029.82513069312, w0=73.50000000000014, w1=16.523966730478875\n",
      "SubSGD iter. 143/499: loss=111572.2686715298, w0=74.20000000000014, w1=15.83727209497274\n",
      "SubSGD iter. 144/499: loss=115410.80894405724, w0=74.90000000000015, w1=14.860474616030821\n",
      "SubSGD iter. 145/499: loss=111869.7696579126, w0=74.20000000000014, w1=15.01093129248195\n",
      "SubSGD iter. 146/499: loss=114632.40332293313, w0=74.90000000000015, w1=15.389471075838681\n",
      "SubSGD iter. 147/499: loss=111944.02302568447, w0=74.20000000000014, w1=16.18930180990139\n",
      "SubSGD iter. 148/499: loss=114736.09179415714, w0=74.90000000000015, w1=15.662113171154164\n",
      "SubSGD iter. 149/499: loss=119569.34094680894, w0=75.60000000000015, w1=15.775933497968477\n",
      "SubSGD iter. 150/499: loss=126232.39335340462, w0=76.30000000000015, w1=16.120401744838944\n",
      "SubSGD iter. 151/499: loss=119744.31212751722, w0=75.60000000000015, w1=15.891280052552185\n",
      "SubSGD iter. 152/499: loss=127110.84901612464, w0=76.30000000000015, w1=16.432237104523328\n",
      "SubSGD iter. 153/499: loss=119589.62805850753, w0=75.60000000000015, w1=15.789307405759532\n",
      "SubSGD iter. 154/499: loss=114827.14291447622, w0=74.90000000000015, w1=15.813273245562623\n",
      "SubSGD iter. 155/499: loss=120460.33159050936, w0=75.60000000000015, w1=16.26345299176892\n",
      "SubSGD iter. 156/499: loss=116667.96618960385, w0=74.90000000000015, w1=16.821576695517958\n",
      "SubSGD iter. 157/499: loss=111517.11193754153, w0=74.20000000000014, w1=15.61556040574751\n",
      "SubSGD iter. 158/499: loss=115014.32141913558, w0=74.90000000000015, w1=15.088371767000284\n",
      "SubSGD iter. 159/499: loss=112142.25695877276, w0=74.20000000000014, w1=14.823586657809516\n",
      "SubSGD iter. 160/499: loss=110601.85912787671, w0=73.50000000000014, w1=14.624825791990991\n",
      "SubSGD iter. 161/499: loss=111800.30478081325, w0=74.20000000000014, w1=15.091407917957566\n",
      "SubSGD iter. 162/499: loss=111525.29229492336, w0=73.50000000000014, w1=14.250217749732924\n",
      "SubSGD iter. 163/499: loss=110379.74420594015, w0=72.80000000000014, w1=14.597301735352914\n",
      "SubSGD iter. 164/499: loss=114546.89286736406, w0=73.50000000000014, w1=13.559787541539373\n",
      "SubSGD iter. 165/499: loss=113922.76397999364, w0=74.20000000000014, w1=14.087843357050023\n",
      "SubSGD iter. 166/499: loss=117967.71046331353, w0=73.50000000000014, w1=13.031442125671132\n",
      "SubSGD iter. 167/499: loss=123001.5033326317, w0=74.20000000000014, w1=12.45843204265651\n",
      "SubSGD iter. 168/499: loss=118960.573664167, w0=73.50000000000014, w1=12.89862729736348\n",
      "SubSGD iter. 169/499: loss=124604.49491403006, w0=72.80000000000014, w1=12.267461957368628\n",
      "SubSGD iter. 170/499: loss=120572.27067530094, w0=73.50000000000014, w1=12.694979042586047\n",
      "SubSGD iter. 171/499: loss=116288.69044876707, w0=74.20000000000014, w1=13.490148767703394\n",
      "SubSGD iter. 172/499: loss=111966.8200956049, w0=73.50000000000014, w1=14.112935174523686\n",
      "SubSGD iter. 173/499: loss=109726.82678820386, w0=72.80000000000014, w1=14.847049497524676\n",
      "SubSGD iter. 174/499: loss=110020.92691375023, w0=73.50000000000014, w1=14.960869824338989\n",
      "SubSGD iter. 175/499: loss=111526.59895676834, w0=74.20000000000014, w1=15.574784237716571\n",
      "SubSGD iter. 176/499: loss=115240.61712659078, w0=74.90000000000015, w1=14.955643082302188\n",
      "SubSGD iter. 177/499: loss=113128.7560760002, w0=74.20000000000014, w1=14.363325121034011\n",
      "SubSGD iter. 178/499: loss=116412.71879817998, w0=74.90000000000015, w1=14.378632787746147\n",
      "SubSGD iter. 179/499: loss=112849.99629624399, w0=74.20000000000014, w1=14.478909886986356\n",
      "SubSGD iter. 180/499: loss=115416.69375488446, w0=74.90000000000015, w1=14.857449670343087\n",
      "SubSGD iter. 181/499: loss=111507.81286036216, w0=74.20000000000014, w1=15.759081934755844\n",
      "SubSGD iter. 182/499: loss=109444.27763561165, w0=73.50000000000014, w1=15.626758408402006\n",
      "SubSGD iter. 183/499: loss=108401.635484991, w0=72.80000000000014, w1=16.04999783317452\n",
      "SubSGD iter. 184/499: loss=109879.15395104526, w0=72.10000000000014, w1=16.868656202980148\n",
      "SubSGD iter. 185/499: loss=108689.1941366508, w0=72.80000000000014, w1=15.51469930894692\n",
      "SubSGD iter. 186/499: loss=108916.13779572144, w0=72.10000000000014, w1=16.07282301269596\n",
      "SubSGD iter. 187/499: loss=111161.4841902169, w0=71.40000000000013, w1=15.577196752227128\n",
      "SubSGD iter. 188/499: loss=117517.90689006977, w0=70.70000000000013, w1=14.630284490484698\n",
      "SubSGD iter. 189/499: loss=111253.20994309236, w0=71.40000000000013, w1=15.510014620317175\n",
      "SubSGD iter. 190/499: loss=114494.82834465927, w0=70.70000000000013, w1=16.35143313004312\n",
      "SubSGD iter. 191/499: loss=111221.86552984508, w0=71.40000000000013, w1=16.61691683226735\n",
      "SubSGD iter. 192/499: loss=114498.19445251914, w0=70.70000000000013, w1=16.366635715805295\n",
      "SubSGD iter. 193/499: loss=110967.97143872285, w0=71.40000000000013, w1=16.334206708037936\n",
      "SubSGD iter. 194/499: loss=109352.32559397646, w0=72.10000000000014, w1=16.612333676839622\n",
      "SubSGD iter. 195/499: loss=110868.6298683794, w0=71.40000000000013, w1=16.084277861328975\n",
      "SubSGD iter. 196/499: loss=109024.4889577335, w0=72.10000000000014, w1=16.29544225589518\n",
      "SubSGD iter. 197/499: loss=108907.72387538294, w0=72.80000000000014, w1=16.573569224696865\n",
      "SubSGD iter. 198/499: loss=109102.44461605832, w0=72.10000000000014, w1=15.615434133795057\n",
      "SubSGD iter. 199/499: loss=110940.65480873024, w0=71.40000000000013, w1=15.859460958504208\n",
      "SubSGD iter. 200/499: loss=108907.42660225679, w0=72.10000000000014, w1=16.002791549098724\n",
      "SubSGD iter. 201/499: loss=111245.1308124039, w0=72.80000000000014, w1=17.368161001762335\n",
      "SubSGD iter. 202/499: loss=110440.17986370991, w0=72.10000000000014, w1=17.079663737204918\n",
      "SubSGD iter. 203/499: loss=108392.6335243491, w0=72.80000000000014, w1=15.895661536811026\n",
      "SubSGD iter. 204/499: loss=109159.64513965478, w0=72.10000000000014, w1=16.442823839044898\n",
      "SubSGD iter. 205/499: loss=108743.46282750736, w0=72.80000000000014, w1=15.46602636010298\n",
      "SubSGD iter. 206/499: loss=111969.86933885324, w0=73.50000000000014, w1=14.112069466069752\n",
      "SubSGD iter. 207/499: loss=112008.03582708776, w0=74.20000000000014, w1=14.907239191187099\n",
      "SubSGD iter. 208/499: loss=115366.45567014643, w0=74.90000000000015, w1=14.883273351384007\n",
      "SubSGD iter. 209/499: loss=111492.97295154673, w0=74.20000000000014, w1=15.719312208656824\n",
      "SubSGD iter. 210/499: loss=109564.41602296979, w0=73.50000000000014, w1=16.277435912405863\n",
      "SubSGD iter. 211/499: loss=108447.8093509488, w0=72.80000000000014, w1=15.749380096895214\n",
      "SubSGD iter. 212/499: loss=108919.88394782541, w0=72.10000000000014, w1=16.096464082515205\n",
      "SubSGD iter. 213/499: loss=108844.43838153436, w0=72.80000000000014, w1=16.545123121299916\n",
      "SubSGD iter. 214/499: loss=109433.70558280092, w0=73.50000000000014, w1=16.169537283013348\n",
      "SubSGD iter. 215/499: loss=108939.94127992468, w0=72.80000000000014, w1=15.28980715318087\n",
      "SubSGD iter. 216/499: loss=109554.60172193692, w0=73.50000000000014, w1=15.433137743775386\n",
      "SubSGD iter. 217/499: loss=113497.88184273402, w0=74.20000000000014, w1=16.973200082162574\n",
      "SubSGD iter. 218/499: loss=110241.48335270674, w0=73.50000000000014, w1=16.618172604632747\n",
      "SubSGD iter. 219/499: loss=110846.63937745652, w0=72.80000000000014, w1=17.242988704443693\n",
      "SubSGD iter. 220/499: loss=109979.35591259702, w0=72.10000000000014, w1=16.90776064914044\n",
      "SubSGD iter. 221/499: loss=111179.94486608813, w0=72.80000000000014, w1=17.34768509202462\n",
      "SubSGD iter. 222/499: loss=109020.21051968781, w0=72.10000000000014, w1=16.289769785197063\n",
      "SubSGD iter. 223/499: loss=108519.13818104142, w0=72.80000000000014, w1=15.67062862978268\n",
      "SubSGD iter. 224/499: loss=110036.30468536644, w0=73.50000000000014, w1=16.52685068228722\n",
      "SubSGD iter. 225/499: loss=111565.76361578342, w0=74.20000000000014, w1=15.830265931046455\n",
      "SubSGD iter. 226/499: loss=109516.5316212148, w0=73.50000000000014, w1=15.486553309863064\n",
      "SubSGD iter. 227/499: loss=112207.19795995747, w0=74.20000000000014, w1=16.365801275759235\n",
      "SubSGD iter. 228/499: loss=115198.48537163956, w0=74.90000000000015, w1=16.110369394657663\n",
      "SubSGD iter. 229/499: loss=111829.52813712068, w0=74.20000000000014, w1=15.053968163278773\n",
      "SubSGD iter. 230/499: loss=114743.81221119652, w0=74.90000000000015, w1=15.67745628556495\n",
      "SubSGD iter. 231/499: loss=111978.43375211477, w0=74.20000000000014, w1=16.212975968391156\n",
      "SubSGD iter. 232/499: loss=110320.116934995, w0=73.50000000000014, w1=16.653171223098127\n",
      "SubSGD iter. 233/499: loss=111676.82323988997, w0=72.80000000000014, w1=17.489210080370942\n",
      "SubSGD iter. 234/499: loss=114385.01086949537, w0=72.10000000000014, w1=18.01616711613979\n",
      "SubSGD iter. 235/499: loss=118806.51859527273, w0=71.40000000000013, w1=18.439406540912305\n",
      "SubSGD iter. 236/499: loss=118642.56585039038, w0=72.10000000000014, w1=18.71753350971399\n",
      "SubSGD iter. 237/499: loss=114947.38414328557, w0=71.40000000000013, w1=17.759398418812186\n",
      "SubSGD iter. 238/499: loss=120365.54263098133, w0=70.70000000000013, w1=18.144682559140314\n",
      "SubSGD iter. 239/499: loss=121561.8295631928, w0=70.00000000000013, w1=17.18654746823851\n",
      "SubSGD iter. 240/499: loss=119936.4921614713, w0=70.70000000000013, w1=18.06579543413468\n",
      "SubSGD iter. 241/499: loss=114266.85054311174, w0=71.40000000000013, w1=17.626107029049496\n",
      "SubSGD iter. 242/499: loss=116815.7794554069, w0=70.70000000000013, w1=17.361321919858728\n",
      "SubSGD iter. 243/499: loss=122459.31980964083, w0=70.00000000000013, w1=17.48182647133777\n",
      "SubSGD iter. 244/499: loss=120094.34505640874, w0=70.70000000000013, w1=18.094818968521327\n",
      "SubSGD iter. 245/499: loss=116985.21396423756, w0=71.40000000000013, w1=18.132106280139197\n",
      "SubSGD iter. 246/499: loss=112018.01764142394, w0=72.10000000000014, w1=17.519308109137786\n",
      "SubSGD iter. 247/499: loss=109613.75729781989, w0=72.80000000000014, w1=16.840961113163242\n",
      "SubSGD iter. 248/499: loss=111076.65940090717, w0=72.10000000000014, w1=17.272753691446663\n",
      "SubSGD iter. 249/499: loss=110898.45808518042, w0=71.40000000000013, w1=16.214838384619107\n",
      "SubSGD iter. 250/499: loss=110045.56465762673, w0=72.10000000000014, w1=15.088905971117935\n",
      "SubSGD iter. 251/499: loss=108673.43843271429, w0=72.80000000000014, w1=15.528830414002117\n",
      "SubSGD iter. 252/499: loss=109191.23340451806, w0=72.10000000000014, w1=16.472336897539236\n",
      "SubSGD iter. 253/499: loss=110896.63612420598, w0=71.40000000000013, w1=16.21162467615737\n",
      "SubSGD iter. 254/499: loss=110054.57104421698, w0=72.10000000000014, w1=15.085692262656199\n",
      "SubSGD iter. 255/499: loss=111250.9009922658, w0=71.40000000000013, w1=15.511478409946939\n",
      "SubSGD iter. 256/499: loss=109376.8353520921, w0=72.10000000000014, w1=16.62978863055842\n",
      "SubSGD iter. 257/499: loss=110386.06270466496, w0=72.80000000000014, w1=17.096370756524994\n",
      "SubSGD iter. 258/499: loss=111606.13909226385, w0=73.50000000000014, w1=17.11167842323713\n",
      "SubSGD iter. 259/499: loss=115219.43032126116, w0=74.20000000000014, w1=17.459645469627546\n",
      "SubSGD iter. 260/499: loss=116824.24790808825, w0=74.90000000000015, w1=16.875332932081655\n",
      "SubSGD iter. 261/499: loss=111529.73094800308, w0=74.20000000000014, w1=15.791457535390354\n",
      "SubSGD iter. 262/499: loss=115394.47430454439, w0=74.90000000000015, w1=16.24163728159665\n",
      "SubSGD iter. 263/499: loss=111715.33204780503, w0=74.20000000000014, w1=15.991356165134592\n",
      "SubSGD iter. 264/499: loss=116401.56457091849, w0=74.90000000000015, w1=16.723320758642227\n",
      "SubSGD iter. 265/499: loss=123416.35721774337, w0=75.60000000000015, w1=17.27652667471834\n",
      "SubSGD iter. 266/499: loss=126537.56825258098, w0=76.30000000000015, w1=16.2390124809048\n",
      "SubSGD iter. 267/499: loss=123056.66186525013, w0=75.60000000000015, w1=17.182518964441922\n",
      "SubSGD iter. 268/499: loss=117762.62118896378, w0=74.90000000000015, w1=17.176091083563577\n",
      "SubSGD iter. 269/499: loss=117613.83101354206, w0=74.20000000000014, w1=17.98420482460551\n",
      "SubSGD iter. 270/499: loss=117789.67804244577, w0=74.90000000000015, w1=17.1843740905428\n",
      "SubSGD iter. 271/499: loss=125881.35931930371, w0=75.60000000000015, w1=17.827303789306594\n",
      "SubSGD iter. 272/499: loss=121053.95244368658, w0=74.90000000000015, w1=17.937477906187336\n",
      "SubSGD iter. 273/499: loss=113745.6763412248, w0=74.20000000000014, w1=17.05774777635486\n",
      "SubSGD iter. 274/499: loss=111810.33202564398, w0=73.50000000000014, w1=17.1679218932356\n",
      "SubSGD iter. 275/499: loss=112473.45806033848, w0=72.80000000000014, w1=17.69487892900445\n",
      "SubSGD iter. 276/499: loss=109052.9575150253, w0=72.10000000000014, w1=16.332127533612702\n",
      "SubSGD iter. 277/499: loss=111142.110110964, w0=71.40000000000013, w1=15.597851790120902\n",
      "SubSGD iter. 278/499: loss=114475.1976531219, w0=70.70000000000013, w1=16.149823222058583\n",
      "SubSGD iter. 279/499: loss=120533.98263724618, w0=70.00000000000013, w1=16.685342904884788\n",
      "SubSGD iter. 280/499: loss=114674.81813434015, w0=70.70000000000013, w1=16.558328459656764\n",
      "SubSGD iter. 281/499: loss=111253.95176833431, w0=71.40000000000013, w1=16.64685597314589\n",
      "SubSGD iter. 282/499: loss=114538.84580269342, w0=70.70000000000013, w1=15.91258022965409\n",
      "SubSGD iter. 283/499: loss=119911.74717812058, w0=70.00000000000013, w1=16.34437280793751\n",
      "SubSGD iter. 284/499: loss=114812.9896328489, w0=70.70000000000013, w1=15.573549741869323\n",
      "SubSGD iter. 285/499: loss=111035.76116456144, w0=71.40000000000013, w1=15.71688033246384\n",
      "SubSGD iter. 286/499: loss=114714.65470932191, w0=70.70000000000013, w1=15.660570717418535\n",
      "SubSGD iter. 287/499: loss=110884.53038865718, w0=71.40000000000013, w1=16.19027169148065\n",
      "SubSGD iter. 288/499: loss=115003.92530825092, w0=70.70000000000013, w1=16.73743399371452\n",
      "SubSGD iter. 289/499: loss=111156.06731114426, w0=71.40000000000013, w1=16.553968214664103\n",
      "SubSGD iter. 290/499: loss=115039.45636041203, w0=70.70000000000013, w1=16.754717751713354\n",
      "SubSGD iter. 291/499: loss=111852.11902232323, w0=71.40000000000013, w1=17.020201453937585\n",
      "SubSGD iter. 292/499: loss=109433.66906395282, w0=72.10000000000014, w1=16.67026352245727\n",
      "SubSGD iter. 293/499: loss=110692.09544165642, w0=72.80000000000014, w1=17.194444073908986\n",
      "SubSGD iter. 294/499: loss=112445.11698891452, w0=72.10000000000014, w1=17.620230221199726\n",
      "SubSGD iter. 295/499: loss=112047.2084894231, w0=72.80000000000014, w1=17.587801213432368\n",
      "SubSGD iter. 296/499: loss=114446.64664365862, w0=72.10000000000014, w1=18.027489618517553\n",
      "SubSGD iter. 297/499: loss=117765.72183739446, w0=72.80000000000014, w1=18.6906339355606\n",
      "SubSGD iter. 298/499: loss=121731.15949082992, w0=73.50000000000014, w1=19.140813681766897\n",
      "SubSGD iter. 299/499: loss=127767.61974359439, w0=74.20000000000014, w1=19.568330766984314\n",
      "SubSGD iter. 300/499: loss=128703.0340553138, w0=73.50000000000014, w1=19.99157019175683\n",
      "SubSGD iter. 301/499: loss=130480.37435680657, w0=74.20000000000014, w1=19.89129309251662\n",
      "SubSGD iter. 302/499: loss=122523.48043427893, w0=73.50000000000014, w1=19.248363393752825\n",
      "SubSGD iter. 303/499: loss=119692.5196711044, w0=74.20000000000014, w1=18.394517123327557\n",
      "SubSGD iter. 304/499: loss=114155.5539384487, w0=73.50000000000014, w1=17.778130174490308\n",
      "SubSGD iter. 305/499: loss=113694.11608305183, w0=72.80000000000014, w1=17.962290952808626\n",
      "SubSGD iter. 306/499: loss=113865.98821036986, w0=72.10000000000014, w1=17.919964396205135\n",
      "SubSGD iter. 307/499: loss=112406.40962879271, w0=72.80000000000014, w1=17.678984481538485\n",
      "SubSGD iter. 308/499: loss=110176.3651077855, w0=73.50000000000014, w1=16.589189458465263\n",
      "SubSGD iter. 309/499: loss=109591.70738125718, w0=72.80000000000014, w1=16.833216283174416\n",
      "SubSGD iter. 310/499: loss=111488.1313758176, w0=73.50000000000014, w1=17.07752900688355\n",
      "SubSGD iter. 311/499: loss=108449.54557399488, w0=72.80000000000014, w1=16.198356694652745\n",
      "SubSGD iter. 312/499: loss=109501.10404871014, w0=72.10000000000014, w1=16.706857812392578\n",
      "SubSGD iter. 313/499: loss=109140.64382770612, w0=72.80000000000014, w1=16.67442880462522\n",
      "SubSGD iter. 314/499: loss=111297.61163875717, w0=73.50000000000014, w1=17.022395851015634\n",
      "SubSGD iter. 315/499: loss=109477.99016440014, w0=72.80000000000014, w1=16.793274158728877\n",
      "SubSGD iter. 316/499: loss=111186.37582363759, w0=73.50000000000014, w1=16.989618752246106\n",
      "SubSGD iter. 317/499: loss=115580.40465195001, w0=74.20000000000014, w1=17.54282466832222\n",
      "SubSGD iter. 318/499: loss=116312.25437946667, w0=74.90000000000015, w1=16.68897839789695\n",
      "SubSGD iter. 319/499: loss=119925.63085321455, w0=75.60000000000015, w1=15.992393646656186\n",
      "SubSGD iter. 320/499: loss=116410.0150652433, w0=74.90000000000015, w1=16.726507969657174\n",
      "SubSGD iter. 321/499: loss=120146.58756502846, w0=75.60000000000015, w1=16.10736681424279\n",
      "SubSGD iter. 322/499: loss=115962.7651086871, w0=74.90000000000015, w1=16.53315296153353\n",
      "SubSGD iter. 323/499: loss=121769.62130365544, w0=75.60000000000015, w1=16.79863666375776\n",
      "SubSGD iter. 324/499: loss=127009.76174000441, w0=76.30000000000015, w1=16.399178891371182\n",
      "SubSGD iter. 325/499: loss=121640.71653787616, w0=75.60000000000015, w1=16.752294642938498\n",
      "SubSGD iter. 326/499: loss=128574.86505007073, w0=76.30000000000015, w1=16.86611496975281\n",
      "SubSGD iter. 327/499: loss=133844.06164819625, w0=77.00000000000016, w1=16.126782170308868\n",
      "SubSGD iter. 328/499: loss=141288.3818910986, w0=77.70000000000016, w1=15.77684423882855\n",
      "SubSGD iter. 329/499: loss=135056.2541515397, w0=77.00000000000016, w1=16.595502608634177\n",
      "SubSGD iter. 330/499: loss=127737.82426482422, w0=76.30000000000015, w1=16.627931616401536\n",
      "SubSGD iter. 331/499: loss=124511.76399554835, w0=75.60000000000015, w1=17.529563880814294\n",
      "SubSGD iter. 332/499: loss=116310.78986919443, w0=74.90000000000015, w1=16.68837371258965\n",
      "SubSGD iter. 333/499: loss=113491.50632262365, w0=74.20000000000014, w1=16.970921531675877\n",
      "SubSGD iter. 334/499: loss=109412.75209021788, w0=73.50000000000014, w1=15.76490524190543\n",
      "SubSGD iter. 335/499: loss=108446.19787316701, w0=72.80000000000014, w1=16.190691389196168\n",
      "SubSGD iter. 336/499: loss=112347.9238942617, w0=73.50000000000014, w1=17.315821349326477\n",
      "SubSGD iter. 337/499: loss=112736.09387873554, w0=72.80000000000014, w1=17.755509754411662\n",
      "SubSGD iter. 338/499: loss=113791.50807022027, w0=72.10000000000014, w1=17.90596643086279\n",
      "SubSGD iter. 339/499: loss=109693.96376369207, w0=72.80000000000014, w1=16.86845223704925\n",
      "SubSGD iter. 340/499: loss=109913.87787543843, w0=72.10000000000014, w1=16.882207433024742\n",
      "SubSGD iter. 341/499: loss=109815.81625816897, w0=72.80000000000014, w1=16.908580083649564\n",
      "SubSGD iter. 342/499: loss=110760.74103726598, w0=72.10000000000014, w1=17.180060265632143\n",
      "SubSGD iter. 343/499: loss=115764.57084142904, w0=71.40000000000013, w1=17.91417458863313\n",
      "SubSGD iter. 344/499: loss=115766.15000002572, w0=70.70000000000013, w1=17.035002276402324\n",
      "SubSGD iter. 345/499: loss=121646.39882231611, w0=70.00000000000013, w1=17.216866119977492\n",
      "SubSGD iter. 346/499: loss=129251.16745866234, w0=69.30000000000013, w1=17.62794130451972\n",
      "SubSGD iter. 347/499: loss=138334.75101525095, w0=68.60000000000012, w1=18.105989506945843\n",
      "SubSGD iter. 348/499: loss=132320.81348672585, w0=69.30000000000013, w1=18.356270623407898\n",
      "SubSGD iter. 349/499: loss=124192.81687226173, w0=70.00000000000013, w1=17.933031198635383\n",
      "SubSGD iter. 350/499: loss=117544.66654759986, w0=70.70000000000013, w1=17.55090521408505\n",
      "SubSGD iter. 351/499: loss=116754.87868771817, w0=71.40000000000013, w1=18.09186226605619\n",
      "SubSGD iter. 352/499: loss=111538.72098396235, w0=72.10000000000014, w1=17.395277514815426\n",
      "SubSGD iter. 353/499: loss=108480.54863696427, w0=72.80000000000014, w1=16.269345101314254\n",
      "SubSGD iter. 354/499: loss=110604.62061436429, w0=73.50000000000014, w1=16.778530945260506\n",
      "SubSGD iter. 355/499: loss=114639.37757055077, w0=74.20000000000014, w1=17.319487997231647\n",
      "SubSGD iter. 356/499: loss=113713.03212879738, w0=73.50000000000014, w1=17.66982493060004\n",
      "SubSGD iter. 357/499: loss=110857.12906717055, w0=72.80000000000014, w1=17.246283677546025\n",
      "SubSGD iter. 358/499: loss=109599.35570056493, w0=73.50000000000014, w1=16.302777194008904\n",
      "SubSGD iter. 359/499: loss=112490.04363525753, w0=74.20000000000014, w1=16.513941588575108\n",
      "SubSGD iter. 360/499: loss=114645.68524221944, w0=74.90000000000015, w1=15.476427394761567\n",
      "SubSGD iter. 361/499: loss=111565.09252744893, w0=74.20000000000014, w1=15.82954314632888\n",
      "SubSGD iter. 362/499: loss=114632.73408648078, w0=74.90000000000015, w1=15.433566903107048\n",
      "SubSGD iter. 363/499: loss=113244.68439258932, w0=74.20000000000014, w1=14.315256682495566\n",
      "SubSGD iter. 364/499: loss=110194.91512144767, w0=73.50000000000014, w1=14.85077636532177\n",
      "SubSGD iter. 365/499: loss=126046.44601848278, w0=74.20000000000014, w1=12.080476668432782\n",
      "SubSGD iter. 366/499: loss=124828.55522645674, w0=74.90000000000015, w1=12.42494491530325\n",
      "SubSGD iter. 367/499: loss=131685.16875082147, w0=75.60000000000015, w1=11.897756276556024\n",
      "SubSGD iter. 368/499: loss=126124.98786998895, w0=74.90000000000015, w1=12.244840262176014\n",
      "SubSGD iter. 369/499: loss=123704.71991489499, w0=75.60000000000015, w1=13.369970222306321\n",
      "SubSGD iter. 370/499: loss=119394.20961184468, w0=74.90000000000015, w1=13.450784527795033\n",
      "SubSGD iter. 371/499: loss=113609.00418316848, w0=74.20000000000014, w1=14.184898850796023\n",
      "SubSGD iter. 372/499: loss=110007.87029921482, w0=73.50000000000014, w1=14.969131578835347\n",
      "SubSGD iter. 373/499: loss=111467.02880301168, w0=72.80000000000014, w1=14.268197581400594\n",
      "SubSGD iter. 374/499: loss=111543.01418419436, w0=73.50000000000014, w1=14.244231741597503\n",
      "SubSGD iter. 375/499: loss=109872.56529108898, w0=72.80000000000014, w1=14.787248202962601\n",
      "SubSGD iter. 376/499: loss=109555.6677991164, w0=72.10000000000014, w1=15.292265934786924\n",
      "SubSGD iter. 377/499: loss=108392.97344133127, w0=72.80000000000014, w1=15.90692691591731\n",
      "SubSGD iter. 378/499: loss=109386.93520796338, w0=73.50000000000014, w1=16.118091310483514\n",
      "SubSGD iter. 379/499: loss=111550.66126221186, w0=74.20000000000014, w1=15.498950155069132\n",
      "SubSGD iter. 380/499: loss=115916.73866869134, w0=74.90000000000015, w1=16.511388492935552\n",
      "SubSGD iter. 381/499: loss=120250.52631175936, w0=75.60000000000015, w1=16.161450561455236\n",
      "SubSGD iter. 382/499: loss=114895.94979996429, w0=74.90000000000015, w1=15.891312111165567\n",
      "SubSGD iter. 383/499: loss=112928.86692203154, w0=74.20000000000014, w1=16.73133968262538\n",
      "SubSGD iter. 384/499: loss=117780.35314825551, w0=74.90000000000015, w1=17.181519428831674\n",
      "SubSGD iter. 385/499: loss=114818.1809853932, w0=74.20000000000014, w1=17.363383272406843\n",
      "SubSGD iter. 386/499: loss=115196.52827488878, w0=73.50000000000014, w1=18.020264240159808\n",
      "SubSGD iter. 387/499: loss=117041.44652637173, w0=72.80000000000014, w1=18.572235672097488\n",
      "SubSGD iter. 388/499: loss=116000.76488937272, w0=73.50000000000014, w1=18.19664983381092\n",
      "SubSGD iter. 389/499: loss=118135.59277441482, w0=72.80000000000014, w1=18.7486212657486\n",
      "SubSGD iter. 390/499: loss=116932.30130990664, w0=73.50000000000014, w1=18.378353175219804\n",
      "SubSGD iter. 391/499: loss=115759.47797571484, w0=74.20000000000014, w1=17.583983830729025\n",
      "SubSGD iter. 392/499: loss=121552.90111541354, w0=74.90000000000015, w1=18.023908273613205\n",
      "SubSGD iter. 393/499: loss=114034.58078900217, w0=74.20000000000014, w1=17.144660307717032\n",
      "SubSGD iter. 394/499: loss=109360.76475131304, w0=73.50000000000014, w1=16.088259076338144\n",
      "SubSGD iter. 395/499: loss=109238.94187457763, w0=72.80000000000014, w1=16.709310649908737\n",
      "SubSGD iter. 396/499: loss=109373.14004945327, w0=73.50000000000014, w1=15.93848758384055\n",
      "SubSGD iter. 397/499: loss=108392.64859577075, w0=72.80000000000014, w1=15.896161027237058\n",
      "SubSGD iter. 398/499: loss=110000.2920624428, w0=73.50000000000014, w1=16.510822008367445\n",
      "SubSGD iter. 399/499: loss=112234.5104788499, w0=74.20000000000014, w1=16.38380756313942\n",
      "SubSGD iter. 400/499: loss=115225.3695786723, w0=74.90000000000015, w1=16.12837568203785\n",
      "SubSGD iter. 401/499: loss=111496.34136453774, w0=74.20000000000014, w1=15.704834428983833\n",
      "SubSGD iter. 402/499: loss=116090.08211022528, w0=74.90000000000015, w1=14.520832228589942\n",
      "SubSGD iter. 403/499: loss=112489.081730674, w0=74.20000000000014, w1=14.631006345470682\n",
      "SubSGD iter. 404/499: loss=112237.56996904736, w0=73.50000000000014, w1=14.038688384202505\n",
      "SubSGD iter. 405/499: loss=112374.9630781346, w0=74.20000000000014, w1=14.69074528164496\n",
      "SubSGD iter. 406/499: loss=110258.6575841244, w0=73.50000000000014, w1=14.811249833124002\n",
      "SubSGD iter. 407/499: loss=112854.65879591004, w0=72.80000000000014, w1=13.931519703291524\n",
      "SubSGD iter. 408/499: loss=110337.00307240909, w0=73.50000000000014, w1=14.7648572858511\n",
      "SubSGD iter. 409/499: loss=112051.9286209779, w0=72.80000000000014, w1=14.107674582656115\n",
      "SubSGD iter. 410/499: loss=110739.12098649527, w0=73.50000000000014, w1=14.556333621440825\n",
      "SubSGD iter. 411/499: loss=112318.27943422273, w0=74.20000000000014, w1=14.72213988100832\n",
      "SubSGD iter. 412/499: loss=109698.11225466279, w0=73.50000000000014, w1=15.274111312946\n",
      "SubSGD iter. 413/499: loss=108392.36944345411, w0=72.80000000000014, w1=15.886909483947411\n",
      "SubSGD iter. 414/499: loss=109759.85582447736, w0=73.50000000000014, w1=15.208562487972868\n",
      "SubSGD iter. 415/499: loss=108632.78945100393, w0=72.80000000000014, w1=15.565288006328705\n",
      "SubSGD iter. 416/499: loss=110287.00309874899, w0=73.50000000000014, w1=14.794464940260518\n",
      "SubSGD iter. 417/499: loss=113367.40990857534, w0=74.20000000000014, w1=14.267276301513292\n",
      "SubSGD iter. 418/499: loss=111644.80684035561, w0=73.50000000000014, w1=14.210966686467987\n",
      "SubSGD iter. 419/499: loss=116694.70569158839, w0=72.80000000000014, w1=13.25283159556618\n",
      "SubSGD iter. 420/499: loss=115404.67906535827, w0=73.50000000000014, w1=13.418637855133676\n",
      "SubSGD iter. 421/499: loss=119075.96467170671, w0=72.80000000000014, w1=12.923011594664844\n",
      "SubSGD iter. 422/499: loss=117181.38049525538, w0=72.10000000000014, w1=13.45853127749105\n",
      "SubSGD iter. 423/499: loss=118294.49771492399, w0=72.80000000000014, w1=13.028199689030313\n",
      "SubSGD iter. 424/499: loss=113915.36774623547, w0=73.50000000000014, w1=13.671129387794108\n",
      "SubSGD iter. 425/499: loss=122530.18034114467, w0=72.80000000000014, w1=12.50279858727664\n",
      "SubSGD iter. 426/499: loss=125855.16655909081, w0=72.10000000000014, w1=12.304037721458116\n",
      "SubSGD iter. 427/499: loss=117336.82468445228, w0=72.80000000000014, w1=13.160259773962654\n",
      "SubSGD iter. 428/499: loss=115313.7210855844, w0=72.10000000000014, w1=13.764025843929169\n",
      "SubSGD iter. 429/499: loss=122278.83353099196, w0=71.40000000000013, w1=13.159493738075009\n",
      "SubSGD iter. 430/499: loss=116345.19515864164, w0=72.10000000000014, w1=13.587010823292427\n",
      "SubSGD iter. 431/499: loss=113141.48196420995, w0=71.40000000000013, w1=14.712943236793599\n",
      "SubSGD iter. 432/499: loss=111091.33309069871, w0=72.10000000000014, w1=14.728250903505735\n",
      "SubSGD iter. 433/499: loss=113981.85265616143, w0=71.40000000000013, w1=14.52949003768721\n",
      "SubSGD iter. 434/499: loss=109866.002973863, w0=72.10000000000014, w1=15.152978159973388\n",
      "SubSGD iter. 435/499: loss=110934.78279510092, w0=71.40000000000013, w1=16.27891057347456\n",
      "SubSGD iter. 436/499: loss=115109.21714453508, w0=70.70000000000013, w1=16.78741169121439\n",
      "SubSGD iter. 437/499: loss=110909.51919048124, w0=71.40000000000013, w1=15.947384119754581\n",
      "SubSGD iter. 438/499: loss=114474.22288634419, w0=70.70000000000013, w1=16.232558614303876\n",
      "SubSGD iter. 439/499: loss=111729.60303038574, w0=71.40000000000013, w1=16.96452320781151\n",
      "SubSGD iter. 440/499: loss=108937.74798309174, w0=72.10000000000014, w1=16.156409466769578\n",
      "SubSGD iter. 441/499: loss=108930.76634848939, w0=72.80000000000014, w1=16.583926551986995\n",
      "SubSGD iter. 442/499: loss=110534.2407527844, w0=72.10000000000014, w1=17.110883587755843\n",
      "SubSGD iter. 443/499: loss=112768.28173117411, w0=72.80000000000014, w1=17.7629404851983\n",
      "SubSGD iter. 444/499: loss=111194.43693734231, w0=73.50000000000014, w1=16.99211741913011\n",
      "SubSGD iter. 445/499: loss=110939.14584778361, w0=72.80000000000014, w1=17.272046411566574\n",
      "SubSGD iter. 446/499: loss=109355.87819353487, w0=72.10000000000014, w1=16.61486370837159\n",
      "SubSGD iter. 447/499: loss=112879.93016306192, w0=71.40000000000013, w1=17.318368626762453\n",
      "SubSGD iter. 448/499: loss=116181.72065532942, w0=72.10000000000014, w1=18.33104696811522\n",
      "SubSGD iter. 449/499: loss=110541.1976955669, w0=72.80000000000014, w1=17.14704476772133\n",
      "SubSGD iter. 450/499: loss=109434.35106065238, w0=73.50000000000014, w1=16.17024728877941\n",
      "SubSGD iter. 451/499: loss=110311.69254848466, w0=72.80000000000014, w1=17.07187955319217\n",
      "SubSGD iter. 452/499: loss=110671.13715413668, w0=72.10000000000014, w1=17.15269385868088\n",
      "SubSGD iter. 453/499: loss=111654.52277314941, w0=71.40000000000013, w1=16.923572166394123\n",
      "SubSGD iter. 454/499: loss=109282.54682184765, w0=72.10000000000014, w1=16.557651435663725\n",
      "SubSGD iter. 455/499: loss=111036.08857344346, w0=71.40000000000013, w1=15.716461267439083\n",
      "SubSGD iter. 456/499: loss=114480.43365378774, w0=70.70000000000013, w1=16.286421391975068\n",
      "SubSGD iter. 457/499: loss=120738.52197537846, w0=70.00000000000013, w1=16.7949225097149\n",
      "SubSGD iter. 458/499: loss=114474.89182118913, w0=70.70000000000013, w1=16.17578135430052\n",
      "SubSGD iter. 459/499: loss=110869.3547149406, w0=71.40000000000013, w1=16.065607237419776\n",
      "SubSGD iter. 460/499: loss=109131.42869463067, w0=72.10000000000014, w1=16.413574283810192\n",
      "SubSGD iter. 461/499: loss=110174.09547334038, w0=72.80000000000014, w1=17.02656678099375\n",
      "SubSGD iter. 462/499: loss=111223.6892954351, w0=72.10000000000014, w1=17.311741275543046\n",
      "SubSGD iter. 463/499: loss=111215.38288851605, w0=71.40000000000013, w1=16.610807278108293\n",
      "SubSGD iter. 464/499: loss=117031.2229316358, w0=70.70000000000013, w1=17.418921019150226\n",
      "SubSGD iter. 465/499: loss=123201.43936837491, w0=70.00000000000013, w1=17.70146883823645\n",
      "SubSGD iter. 466/499: loss=119083.58538250349, w0=70.70000000000013, w1=17.897988921014953\n",
      "SubSGD iter. 467/499: loss=121175.88688925274, w0=70.00000000000013, w1=17.018816608784146\n",
      "SubSGD iter. 468/499: loss=129081.51574752989, w0=69.30000000000013, w1=17.576940312533186\n",
      "SubSGD iter. 469/499: loss=134126.7296032112, w0=68.60000000000012, w1=16.493064915841884\n",
      "SubSGD iter. 470/499: loss=127569.67832602677, w0=69.30000000000013, w1=17.046270831917997\n",
      "SubSGD iter. 471/499: loss=121632.0546129747, w0=70.00000000000013, w1=17.211723623850624\n",
      "SubSGD iter. 472/499: loss=115276.96979336308, w0=70.70000000000013, w1=16.858607872283308\n",
      "SubSGD iter. 473/499: loss=121853.784463917, w0=70.00000000000013, w1=17.29040045056673\n",
      "SubSGD iter. 474/499: loss=126743.55750043543, w0=69.30000000000013, w1=16.633217747371745\n",
      "SubSGD iter. 475/499: loss=134944.89169127058, w0=68.60000000000012, w1=17.05645717214426\n",
      "SubSGD iter. 476/499: loss=144528.1020864056, w0=67.90000000000012, w1=17.300483996853412\n",
      "SubSGD iter. 477/499: loss=140391.21847118528, w0=68.60000000000012, w1=18.539800297831412\n",
      "SubSGD iter. 478/499: loss=133196.01321020452, w0=69.30000000000013, w1=18.515834458028323\n",
      "SubSGD iter. 479/499: loss=136978.7121949009, w0=68.60000000000012, w1=17.769848804440926\n",
      "SubSGD iter. 480/499: loss=131909.8783397755, w0=69.30000000000013, w1=18.279034648387178\n",
      "SubSGD iter. 481/499: loss=122127.47835941953, w0=70.00000000000013, w1=17.37740238397442\n",
      "SubSGD iter. 482/499: loss=115046.74085610331, w0=70.70000000000013, w1=16.758261228560038\n",
      "SubSGD iter. 483/499: loss=119613.66799376988, w0=70.00000000000013, w1=16.15372912270588\n",
      "SubSGD iter. 484/499: loss=114475.47563663636, w0=70.70000000000013, w1=16.26402915616667\n",
      "SubSGD iter. 485/499: loss=111338.54488604242, w0=71.40000000000013, w1=15.455915415124739\n",
      "SubSGD iter. 486/499: loss=112036.82528517047, w0=72.10000000000014, w1=14.428983217532206\n",
      "SubSGD iter. 487/499: loss=113357.10923694816, w0=72.80000000000014, w1=13.825217147565692\n",
      "SubSGD iter. 488/499: loss=112301.75904679326, w0=73.50000000000014, w1=14.02156174108292\n",
      "SubSGD iter. 489/499: loss=112073.04505904004, w0=72.80000000000014, w1=14.102376046571631\n",
      "SubSGD iter. 490/499: loss=114918.67740450196, w0=73.50000000000014, w1=13.498609976605117\n",
      "SubSGD iter. 491/499: loss=112820.22296563174, w0=72.80000000000014, w1=13.938805231312088\n",
      "SubSGD iter. 492/499: loss=118037.87037503811, w0=72.10000000000014, w1=13.333402079868103\n",
      "SubSGD iter. 493/499: loss=118478.8168537804, w0=71.40000000000013, w1=13.728838871811108\n",
      "SubSGD iter. 494/499: loss=125083.20054029628, w0=70.70000000000013, w1=13.305297618757093\n",
      "SubSGD iter. 495/499: loss=126578.25484914776, w0=70.00000000000013, w1=13.810315350581416\n",
      "SubSGD iter. 496/499: loss=122459.08259066714, w0=70.70000000000013, w1=13.710038251341206\n",
      "SubSGD iter. 497/499: loss=122887.079846082, w0=70.00000000000013, w1=14.55145676106715\n",
      "SubSGD iter. 498/499: loss=115220.40516520276, w0=70.70000000000013, w1=15.269620085098339\n",
      "SubSGD iter. 499/499: loss=111426.65381602956, w0=71.40000000000013, w1=15.401943611452177\n",
      "SubSGD: execution time=0.043 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c58f69052346c586a87edde0be9a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
